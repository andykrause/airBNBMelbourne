---
title: "Should I AirBNB My Property?"
author: "Andy Krause and Gideon Aschwanden"
date: "1 November 2016"
output:
  html_notebook: default
  pdf_document: default
---

&nbsp;

## Introduction

&nbsp;

This document is the literate programming of our analysis for the 'Should I AirBNB My Property?' research project.  Below we document the complete data provenance, taking our data from the raw source data through to the final results. Data prepartion, modeling and visualization will be done in R (version 3.3.1). As a very brief overview, we will be comparing the financial returns of short-term (AirBNB-type) and long-term (traditional leases) leasing of residential properties in Melbourne, Australia.  We perform this comparison under a hypothetical condition where-in an investor purchases a property on Septemeber 1, 2015 and is looking to determine whether to lease out the property on a traditional long-term lease (12 months) or nightly as an AirBNB property.  We examine the returns for the following 12 months.  Sensitivity to time frames, start dates, locations, property types, etc. are considered in this analysis as well. 

Data on AirBNB (short-term) rentals have been purchased from www.airdna.co, a data provider specializing in AirBNB data collection and analysis. The data on long-term leases was provided by Australia Property Monitors (APM), a Fairfax Group company. 

Throughout this document we will refer to the short-term data as **'short-term'** or **'AirBNB'** while the long-term data will be referred to as **'long-term'**, **'rental'** or **'lease'**.  Short-term nightly fees will be referenced as **'rates'** and long-term as **'rent'**.  We will use **'prices'** to collectively refer to **rates** and **rents**. Note that within the Melbourne long term rentals are quoted in weekly rents but are charged to tenants at a monthly rent equivalent to 1/12 of 52 weeks of rent. 

&nbsp;

### Preliminary Commands

&nbsp;

We begin with a number of preliminary commands.  First we load all of the necessary R libraries for this analysis. 

```{r load_libraries, message=FALSE, warning=FALSE, comment=FALSE, echo=TRUE, results='hide'}

  library(spdep)
  library(maptools)
  library(gstat)
  library(ggplot2)
  library(geosphere)
  library(ggmap)
  library(xtable)
  library(chron)
  library(plyr)
  library(sp)
  library(rgeos)
  library(reshape2)
  library(stringr)
  library(RColorBrewer)
  library(Hmisc)

```

We then set the paths to the data and the code, conditional on which of the authors is running the analysis.

```{r set_paths, message=FALSE, warning=FALSE, comment=FALSE, echo=TRUE, results='hide'}

  # Get computer names

  comp.name <- Sys.info()['nodename']

  # Assign path based on computer name
  
  if(comp.name == '7020D-121777-W' | comp.name == 'DESKTOP-1D7JO4J'){
  
    data.path <- 'c:/dropbox/research/airBNB/data/'
    code.path <- 'c:/code/'

  } else {
  
    data.path <- 'alternate data path'
    code.path <- 'alternate data path'
    
  }

```
 
Next, we source the necessary custom code files for the analysis.  
  
```{r source_files, message=FALSE, warning=FALSE, comment=FALSE, echo=TRUE, results='hide'}

  source(paste0(code.path, "dataviztools/ggplottools.R"))
  source(paste0(code.path, "datamgmttools/dataMungetools.R"))
  source(paste0(code.path, "research/AirBNBMelbourne/analysis_Functions.R"))
  source(paste0(code.path, "research/AirBNBMelbourne/dataPrep_Functions.R"))
  source("c:/code/spatialtools/point2surface_Tools.R")
  source("c:/code/spatialtools/spatiallogitmodels.R")
  
```

We then set the constants used in this study:

1. **Exchange rate**: The Airbnb rates are provided in US dollars.  We convert these to Australian dollars based on the average exchange rate over the Sep 1 2015 to Aug 30 2015 period, or about 1.32 Australian dollars to 1 US dollar.

```{r set_constants, message=FALSE, warning=FALSE, comment=FALSE, echo=TRUE, results='hide'}

  exch.rate <- 1.32  

```

Finally, we set the color to be used in the analysis.  We use AirBnb's official palette of 10 colors.

```{r set_colors, message=FALSE, warning=FALSE, comment=FALSE, echo=FALSE}

 # Set all colors

  abb.colors.names=c('rausch', 'hackberry', 'kazan', 'babu', 'lima', 'beach',
                     'ebisu', 'tirol', 'foggy', 'hof')
  abb.col <- c(rgb(250,88,99, maxColorValue=255), rgb(139,14,82, maxColorValue=255),
               rgb(0,117,140, maxColorValue=255), rgb(4,211,191, maxColorValue=255), 
               rgb(77,226,110, maxColorValue=255), rgb(252,179,14, maxColorValue=255),
               rgb(249,177,139, maxColorValue=255), rgb(191,166,100, maxColorValue=255),
               rgb(156,161,155, maxColorValue=255), rgb(86,94,97, maxColorValue=255))

  # Set specific colors
  
  str.col <- abb.col[1]
  ltr.col <- abb.col[3]
  
  
```

&nbsp;

### Data Pre-processing

&nbsp;

Both the AirBNB and the long term rental data require some measure of data pre-processing and due to the run times of these processes they are done outside of this document.  For the AirBNB data, the pre-processing is primarily concerned with imputing missing daily observations for a small number of properties in the dataset.  Full information on this process can be found in the **airbnbDataClean.Rmd** and **dataCleanFunctions.R** files.  Do note that most of the imputed data is ignored by our choice of study time period.

The long term data received from the data provider is both wide and long and very inefficiently stored.  To aid in computation time, the pre-processing involves the trimming of fields, labeling of observation types and reconfiguration of data and can be found in the **fixAPMData.R** script. 

&nbsp;

## Loading data

&nbsp;

Next we load in the raw data.  The Airbnb data is found in two separate files, one providing information on the property itself and one providing a daily record of bookings.  
```{r load_abb_data, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Property Information

  abb.data <- read.csv(paste0(data.path, '/prepared/propdata.csv'), header=T)

  # Daily ltral information

  daily.data  <- read.csv(paste0(data.path, '/prepared/dailydata.csv'), header=T)

```

We then load the long term rental data.  This includes property level data (including the final lease rate) and listing-level data containing information on all changes to listing prices and dates, etc. 

```{r load_ltr_data, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 # Property level long term ltral information

  ltr.data <- read.csv(paste0(data.path, '/prepared/ltpropdata.csv'), header=T)

 # Long term ltral listing information

  listing.data <- read.csv(paste0(data.path, '/prepared/ltlistdata.csv'), header=T)

```

And, finally, we load three GIS shapefiles.  The first two denote suburb and Statistical Area 1 (sa1) boundaries in the Melbourne area. We also load a shapefile that contains the location of the beach areas along Port Phillip Bay.^[Only those east of the mouth of Yarra River as those to the west are primarily industrial land.]

```{r load_sp_data, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Suburb shapefile

  suburbs.shp <- readShapePoly(paste0(data.path, 'geographic/melbSuburbs.shp'),
                               proj4string=CRS("+init=epsg:4283"),
                               delete_null_obj=TRUE)

  # SA1 shapefile

  sa1s.shp <- readShapePoly(paste0(data.path, 'geographic/sa1s.shp'),
                            proj4string=CRS("+init=epsg:4283"),
                            delete_null_obj=TRUE)

  # Beach file

  beach.shp <- readShapePoly(paste0(data.path, 'geographic/portPhillipBeach.shp'),
                             proj4string=CRS("+init=epsg:4283"),
                             delete_null_obj=TRUE)

```

&nbsp;

## Data Preparation

&nbsp;

In this section we remove, convert and/or transform a number of data fields.  We also remove observations if they are missing critical data or fall outside of the scope of our research question. 

&nbsp;

### Trim and Standardize Fields

&nbsp;

We start by converting all field names to lower case to simplify future coding.  This is important as R is case sensitive.  

```{r lower_names, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
 # Short term data  
  
  names(abb.data) <- tolower(names(abb.data))
  names(daily.data) <- tolower(names(daily.data))
  
 # Long term data  
  
  names(ltr.data) <- tolower(names(ltr.data))
  names(listing.data) <- tolower(names(listing.data))
  
 # Geographic data  
  
  names(sa1s.shp@data) <- tolower(names(sa1s.shp@data))
  names(suburbs.shp@data) <- tolower(names(suburbs.shp@data))
  
```

The data contain many fields that are either not fully observed and/or are not relevant to our research question.  Additionally, the field naming conventions differ between the two datasets.  We first remove unnecessary or unobserved fields and then employ a systematic field naming functions across all datasets.

We start by trimming the property-level short term data.  No fields need to be removed from the daily data. 
  
```{r trim_st, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  abb.keep.flds <- c('property.id', 'host.id', 'listing.title', 'property.type',
                     'listing.type', 'created.date', 'latitude', 'longitude',
                     'last.scraped.date', 'average.daily.rate', 'overall.rating',
                     'max.guests', 'cancellation.policy', 'cleaning.fee',
                     'published.nightly.rate', 'published.weekly.rate', 
                     'published.monthly.rate', 'minimum.stay',
                     'bedrooms', 'bathrooms', 'min.date', 'max.date', 'total.days',
                     'blocked.days', 'available.days', 'created.year') 
  
  abb.data <- abb.data[, abb.keep.flds]

```

We then limit the fields of the long-term property-specific data

```{r trim_lt, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  ltr.keep.flds <- c('id.key', 'geographicalid', 'eventid', 'addressid', 'activityid',
                      'flatnumber', 'streetnumber', 'streetname', 'streettype', 
                      'suburb', 'postcode', 'property_latitude',
                      'property_longitude', 'street_centroid_latitude',
                      'street_centroid_longitude', 'eventdate', 'eventprice',
                      'propertytype', 'areasize', 'bedrooms', 'baths', 'parking',
                      'hasstudy', 'hascourtyard', 'hasbalcony', 'hasairconditioning',
                      'hasgarage', 'dom') 
  

  ltr.data <- ltr.data[,ltr.keep.flds]
  
```

Next we standardize the field names.  Here we follow the short-term data convention of placing a period between words in the name.  We also shorten a number of the fields to make future coding easier.  

For the short term data, it already uses the *word-.-word* convention.  Here our renaming is done to shorten certain field names. No changes are made to the names of the Airbnb daily data. 

```{r rename_st, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
  names(abb.data) <- c('property.id', 'host.id', 'listing.title', 'property.type',
                       'listing.type', 'created.date', 'latitude', 'longitude',
                       'last.scraped.date', 'average.daily.rate', 'overall.rating',
                       'max.guests', 'cancel.policy', 'cleaning.fee',
                       'nightly.rate', 'weekly.rate', 'monthly.rate', 'min.stay',
                       'bedrooms', 'baths', 'min.date', 'max.date', 'total.days',
                       'blocked.days', 'available.days', 'created.year')

```

Periods are inserted between relevant words for the ltral data. 

```{r rename_lt, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
  names(ltr.data) <- c('id.key', 'geographical.id', 
                        'event.id', 'address.id', 'activity.id',
                        'flat.number', 'street.number', 'street.name', 'street.type',
                        'suburb', 'postcode', 'latitude', 'longitude',
                        'street.latitude', 'street.longitude', 'event.date',
                        'event.price', 'property.type', 'area.size', 'bedrooms',
                        'baths', 'parking', 'has.study', 'has.courtyard',
                        'has.balcony', 'has.aircond', 'has.garage', 'dom')

  names(listing.data) <- c('id.key', 'event.id', 'activity.id', 'address.id', 
                           'of.record', 'event.date', 'event.price', 'first.adv.date', 
                           'first.adv.price', 'last.adv.date', 'last.adv.price',
                           'event.type')

```

&nbsp;

### Temporal Considerations

&nbsp;

Below we rename, transform and filter our data to fit the time period appropriate to our research question.  

&nbsp;

#### Convert Time Variables

We convert time variables across all dataset to an R date format.  For the AirBNB data this is a relatively straighforword process as the data are already standardized into a consistant date representation. We fix dates in both the property and the daily data. 

```{r fix_st_time, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Property Data Fields

  abb.data$created.date <- as.Date(abb.data$created.date)
  abb.data$last.scraped.date <- as.Date(abb.data$last.scraped.date)
  abb.data$min.date <- as.Date(abb.data$min.date)
  abb.data$max.date <- as.Date(abb.data$max.date)
  
  # Daily Data  

  daily.data$date <- as.Date(daily.data$date)

```

The dates in the long term data are not standardized.  To fix this issue we create a small function that will remove the unnecessary digits and spaces and then convert to a standard date form.  We then apply this formula to the three date fields in the long term data (both listing and rental).  We also create a year field for the event date. 

```{r fix_lt_time, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 # Build custom function  

  fixLTDates <- function(x){
    temp.date <- as.character(x)
    temp.date <- str_replace_all(temp.date, ' 0:00', '')
    temp.date <- str_replace_all(temp.date, '/20', '/')
    return(as.Date(temp.date, "%d/%m/%y"))   
  }

  # Convert event date  

  ltr.data$event.date <- fixLTDates(ltr.data$event.date)

  # Extract Year of event date
  ltr.data$event.year <- as.numeric(substr(ltr.data$event.date, 1, 4))

  # Converted listing data date fields  

  listing.data$first.adv.date <- fixLTDates(listing.data$first.adv.date)
  listing.data$last.adv.date <- fixLTDates(listing.data$last.adv.date)

```

#### Trim by Time

Next we trim the observations by time.  Our hypothetical simulated decision is that of an investor who purchases a property on September 1, 2015 and must decide on traditional long term rental versus an AirBNB, short term rental approach to generating income.  To determine the likely long term rental rate for any given property, we will use the observed rental transactions from the market from September 1, 2014 to August 31, 2015.  Taking the AirBNB approach allows the owner to change rates over time and is subjected to daily changes in the market (supply and demand factors).  In this simulated example we will use AirBnB data from September 1, 2015 to August 31, 2016 to represent the actual AirBNB market conditions over the time period in question.  Another reason for using these two period of data is that the AirBNB data has missing daily values prior to September 1, 2015.  While we have imputed these missing daily observations, we hold the actual observed values to be of greater accuracy and have designed the initial simulated example to take advantage of the full observed set. 

```{r}

setCleanCount <- function(){
  
  abb.orig <- nrow(abb.data)
  daily.orig <- nrow(daily.data)
  ltr.orig <- nrow(ltr.data)
  list.orig <- nrow(listing.data)
  
  clean.df <- data.frame(operation='initial',
                         abb=abb.orig,
                         daily=daily.orig,
                         ltr=ltr.orig,
                         list=list.orig)
  assign('clean.count', clean.df, envir=.GlobalEnv)
  assign('abb.run.total', nrow(abb.data), envir=.GlobalEnv)
  assign('ltr.run.total', nrow(ltr.data), envir=.GlobalEnv)
  assign('list.run.total', nrow(listing.data), envir=.GlobalEnv)
  assign('daily.run.total', nrow(daily.data), envir=.GlobalEnv)
  
}

countCleaning <- function(operation){
  
  abb.cut <- abb.run.total - nrow(abb.data)
  daily.cut <- daily.run.total - nrow(daily.data)
  ltr.cut <- ltr.run.total - nrow(ltr.data)
  listing.cut <- list.run.total - nrow(listing.data)

  new.df <- data.frame(operation=operation,
                       abb=abb.cut,
                       daily=daily.cut,
                       ltr=ltr.cut,
                       list=listing.cut)
  comb.df <- rbind(clean.count, new.df)
  assign('clean.count', comb.df, envir=.GlobalEnv)
  assign('abb.run.total', nrow(abb.data), envir=.GlobalEnv)
  assign('ltr.run.total', nrow(ltr.data), envir=.GlobalEnv)
  assign('list.run.total', nrow(listing.data), envir=.GlobalEnv)
  assign('daily.run.total', nrow(daily.data), envir=.GlobalEnv)
  
}

setCleanCount()

```



```{r clip_time, message=FALSE, warning=FALSE, comment=FALSE, cache=FALSE, echo=TRUE}
 
 # Limit short term data

  abb.data <- abb.data[abb.data$min.date >= '2015-09-01', ]
  daily.data <- daily.data[daily.data$date >= '2015-09-01', ]

 # Limit long term data  
  
  ltr.data <- ltr.data[ltr.data$event.date >= '2014-09-01' & 
                            ltr.data$event.date <= '2015-08-31', ]
  listing.data <- listing.data[listing.data$id.key %in% ltr.data$id.key, ]
  
 # Count cleaning
  
  countCleaning('time')
  
```

```{r add_month, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Short term data

  abb.data$abb.month <- 1
  daily.data$abb.month <- as.numeric(as.factor(substr(daily.data$date, 1, 7)))

  # Long term data

  ltr.data$ltr.month <- as.numeric(as.factor(substr(ltr.data$event.date, 1, 7)))
  listing.data$ltr.month <- as.numeric(as.factor(substr(
    listing.data$event.date, 1, 7))) - 8
  
```

### Standardize Property Types

&nbsp;

AirBNB units are classified into 19 different property type.  The most common are Apartments and Houses, the least common are Igloo, Tent, Treehouse and Yurt^[Property types are owner/lister defined, therfore it is likely that the Igloo, at the very least, is not a completely true representation of the property type]. For the sake of this analysis, we will collapse these twenty types into three types:
  
1. **House**:  Includes properties labeled 'House' or 'Townhouse'
2. **Apartment**: Includes properties labeled as 'Apartment' or 'Condominium'
3. **Other**: Includes properties labeled as 'Bed & Breakfast', 'Boat', 'Bungalow', 'Cabin', 'Camper/RV', 'Chalet', 'Dorm', 'Earth House', 'Hut', 'Igloo', 'Loft', 'Other', 'Tent', 'Treehouse', Villa' and 'Yurt. 

Within the long-term rental data, property types fall into eight categories.  Like the AirBNB data we group these into three categories matching as best as possible to the AirBNB categories:
  
1. **House**:  Includes properties labeled 'Duplex', 'House', 'Terrace' or 'Townhouse'
2. **Apartment**: Includes properties labeled as 'Unit' or 'Studio'
3. **Other**: Includes properties labeled as 'Semi' and 'Villa'

Part of the difficulty in perfectly mapping property types from these two datasets is due to the fact that the long-term data uses Australian terms while the AirBNB data conforms to North American lexicon.  This is most apparent when talking about apartment dwellings.  In Australia these are referred to as Units, while in North American they are referred to as Apartments or Condominiums (depending on ownership structure).  Additionally, Terrace homes are very common in many of the older suburbs of Melbourne and would be considered Rowhouses or, likely, Townhomes in the North American context. 

We then create a new variable in each dataset and give each one of the three categories discussed above.

```{r fix_type, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 # Short Term data  

  abb.data$type <- 'Other'
  abb.data$type[abb.data$property.type %in% c('Apartment', 'Condominium')] <- 'Apartment'
  abb.data$type[abb.data$property.type %in% c('House', 'Townhouse')] <- 'House'

 # Long Term data  

  ltr.data$type <- 'Other'
  ltr.data$type[ltr.data$property.type %in% c('Duplex', 'House',
                                           'Terrace', 'Townhouse')] <- 'House'
  ltr.data$type[ltr.data$property.type %in% c('Studio', 'Unit')] <- 'Apartment'

```

As the chart below show, the **Other** category only makes up a very small percentage of the properties in both the short and long term market, especially in the long-term market.  Additionally, a good portion of the **Others** in the Airbnb data are Bed & Breakfast units, a use which doesn't fit with our research question.  As a result, we remove the 'Others' from both the Airbnb and the long term rental data. 

```{r write_beforeproptypeobj, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

before.PT <- list(abb.data=abb.data,
                  ltr.data=ltr.data)


#save(before.PT, subs, file="C:/Dropbox/Research/airBNB/data/analyzed/abb_beforePT.RData")


```

```{r type_comp, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE, fig.height=4}

  # Create Airbnb plot

  abb.types <- ggplot(abb.data, aes(x=type)) + 
    geom_bar(color=str.col, fill=str.col) +
    xlab('\nProperty Type\n') + 
    ggtitle('\nShort Term Rentals\n')  +
    ylab('# of Properties\n')

  # Create long term rental plot

  ltr.types <- ggplot(ltr.data, aes(x=type)) + 
    geom_bar(color=ltr.col, fill=ltr.col) +
    xlab('\nProperty Type\n') + 
    ggtitle('\nLong Term Rentals\n')  +
    ylab('# of Properties\n')

  # Output plots
  
  ggMultiPlots(abb.types, ltr.types, cols=2)
  
```

```{r remove_others, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE, fig.height=4}

  abb.data <- subset(abb.data, type != 'Other')
  ltr.data <- subset(ltr.data, type != 'Other')
  
  countCleaning('property.type')

```

Next, for the short term rentals properties can be listed as one of three types relating to the extent of the property which is able to be booked:

1. **Entire Home/Apt**: The entire home or apartment is available
2. **Private Room**: One room within a house or apartment is available
3. **Shared Room**: A bed within a room shared by another occupant(s) is available

As long-term rentals do not offer **Private Room** or **Shared Room** options^[Our dataset does not include rooming houses, purpose built student accomodations and other types of rental which may offer private or shared room options] and our purpose here is a comparison of long and short term returnw, we remove all short term properties that do not lease the entire home/apt. Unfortunately, this filter does remove about 40% of the short term data, however, given the research question it is unavoidable. 

```{r ltype_comp, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE, fig.height=4}

  # Fix data types and names
  
  abb.data$listing.type <- as.character(abb.data$listing.type)
  abb.data$listing.type[abb.data$listing.type == 'Entire home/apt'] <- 'Entire home'

  # Make Plot
  
  ggplot(abb.data, aes(x=listing.type)) + 
    geom_bar(color=abb.col[1], fill=abb.col[1]) +
    xlab('\nListing Type\n') + 
    ggtitle('\nShort Term Rentals by Listing Type\n')  +
    ylab('# of Properties\n')
  
```

```{r keep_entire_home, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  abb.room <- abb.data[abb.data$listing.type != 'Entire home', ]
  abb.data <- abb.data[abb.data$listing.type == 'Entire home', ]
  
  countCleaning('listing.type')

```


## Structural Characteristics

&nbsp;

In this section we transform and filter based on the structural characteristics of the properties. 

### Fix Boolean Variables

Before beginning, we fix a few of the boolean variables in the long term data that are stored in a non-compatible format.

```{r fix_lt_bools, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  ltr.data$has.study <- ifelse(ltr.data$has.study == 'True', 1, 0)
  ltr.data$has.courtyard <- ifelse(ltr.data$has.courtyard == 'True', 1, 0)
  ltr.data$has.aircon <- ifelse(ltr.data$has.aircon == 'True', 1, 0)
  ltr.data$has.balcony <- ifelse(ltr.data$has.balcony == 'True', 1, 0)
  ltr.data$has.garage <- ifelse(ltr.data$has.garage == 'True', 1, 0)

```

&nbsp;

### Bedrooms

We start by looking at bedrooms. We begin by removing all properties that are missing bedrooms information or have a likely data error in this fields (more than 14 bedrooms). We then plot the distribution of diffeltr bedrooms counts.  From this point onwards we bifurcate our analysis between houses and apartments as the markets (prices, rates, and properties) differ between the two property types. 

```{r bed_fltr, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 # Remove missing and data errors

  # Long term data
  ltr.data <- ltr.data[!is.na(ltr.data$bedrooms), ]
  ltr.data <- ltr.data[ltr.data$bedrooms <= 10, ]

  # Short term data
  abb.data <- abb.data[!is.na(abb.data$bedrooms), ]
  abb.data <- abb.data[abb.data$bedrooms <= 10, ]

```

```{r bed_fltr2, message=FALSE, warning=FALSE, comment=FALSE, cache=FALSE, echo=TRUE, fig.height=5}

 # Build long term bar plot

   ltrbed <- ggplot(ltr.data, aes(x=bedrooms)) + 
    geom_bar(fill=ltr.col, color=ltr.col) +
    facet_wrap(~type) +
    scale_x_continuous(labels=1:10, breaks=1:10)+
    xlab('\nBedrooms\n') +
    ylab('') +
    ggtitle('Bedrooms in Long Term Rentals')
 
 # Build short term bar plot

  abbbed <- ggplot(abb.data, aes(x=bedrooms)) + 
    geom_bar(fill=str.col, color=str.col) +
    facet_wrap(~type) +
    scale_x_continuous(labels=0:10, breaks=0:10)+
    xlab('\nBedrooms\n') +
    ylab('') +
    ggtitle('Bedrooms in Short Term Rentals')
 
 # Make the comparison plot  
  
  ggMultiPlots(abbbed, ltrbed, cols=1)

```

For both short and long term ltrals we see that most apartments have less than 4 bedrooms and houses less than 5.  We filter the data accordingly. Additionally, note that short term ltrals consider studio apartments to be 0 bed units while the long term data considers these as 1 bedroom. We convert the 0 bed short term units to 1 bed units.   

```{r bed_fltr3, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 # Remove all with more than 4 beds

  abb.data <- abb.data[abb.data$bedrooms < 5, ]
  ltr.data <- ltr.data[ltr.data$bedrooms < 5, ]

 # Remove apartments with more than 3
  
  abba <- which(abb.data$bedrooms > 3 & abb.data$type =='Apartment')
  ltra <- which(ltr.data$bedrooms > 3 & ltr.data$type =='Apartment')

  if(length(abba) > 0) abb.data <- abb.data[-abba, ]
  if(length(ltra) > 0) ltr.data <- ltr.data[-ltra, ]

  # Convert 0 Bed to 1 Bed  
  abb.data$bedrooms[abb.data$bedrooms == 0] <- 1
  
  countCleaning('bedrooms')

```

### Bathrooms

We then turn to bathrooms, starting by looking at the distribution of baths between short/long and apt/house.  

```{r bath_fltr, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 # Remove missing data
  
  ltr.data <- ltr.data[!is.na(ltr.data$baths), ]
  abb.data <- abb.data[!is.na(abb.data$baths), ]

```

```{r bath_fltr2, message=FALSE, warning=FALSE, comment=FALSE, cache=FALSE, echo=TRUE, fig.height=5}

 # Build long term plot

  ltbath <- ggplot(ltr.data, aes(x=baths)) + 
    geom_bar(fill=ltr.col, color=ltr.col) +
    facet_wrap(~type) +
    scale_x_continuous(labels=1:8, breaks=1:8)+
    xlab('\nBathrooms\n') +
    ylab('') + 
    ggtitle('Bathrooms in Long Term Rentals')

 # Build short term plot 

  stbath <- ggplot(abb.data, aes(x=baths)) + 
    geom_bar(fill=str.col, color=str.col) +
    facet_wrap(~type) +
    scale_x_continuous(labels=0:8, breaks=0:8)+
    xlab('\nBathrooms\n') +
    ylab('') + 
    ggtitle('Bathrooms in Short Term ltrals')
 
 # Make Plots  
  
  ggMultiPlots(stbath, ltbath, cols=1)

```

Here we see that nearly all properties have 3 or fewer bathrooms and we filter the data accordingly. A few short term properties state no baths, which is likely an error so we remove these as well. Also, here we notice that the short term data gives bathrooms in halves, while the long term data presents baths in whole numbers.  We round the baths up to whole integers. 

```{r bath_fltr3, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 # Filter by bath count

  # Short term data
  abb.data <- abb.data[abb.data$baths < 4, ]
  abb.data <- abb.data[abb.data$baths > 0, ]

  # Long term data
  ltr.data <- ltr.data[ltr.data$baths < 4, ]
  
 # Round baths up  

  abb.data$baths <- round(abb.data$baths + .01, 0)

  countCleaning('bathrooms')
  
  
```

### Bed/Bath Combination

In addition to looking at bedrooms and bathrooms as separate dimensions of properties, they can also be considered together.  In other words, it is very common in the industry (and when looking for a short term ltral) to specify searches by bed/bath combination for obvious reasons -- 1 bedroom with 3 baths is inefficient and 4 bedrooms with 1 bath is uncomfortable.  As a result we examine the combinations of the two. 

```{r filtBB, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 # Create combination variable

  ltr.data$bedbath <- paste0(ltr.data$bedrooms, '..', ltr.data$baths)
  abb.data$bedbath <- paste0(abb.data$bedrooms, '..', abb.data$baths)

```

```{r filtBB2, message=FALSE, warning=FALSE, comment=FALSE, cache=FALSE, echo=TRUE, fig.height=5}

 # Make long term plot

  ltb <- ggplot(ltr.data, aes(x=bedbath)) + 
    geom_bar(fill=ltr.col, color=ltr.col) +
    xlab('\nBed/Bath Combo\n') +
    ylab('Number of Properties\n') +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    ggtitle('Long Term Rentals') + 
    facet_wrap(~type)

 # Make short term plots

  stb <- ggplot(abb.data, aes(x=bedbath)) +
    geom_bar(fill=str.col, color=str.col) + 
    xlab('\nBed/Bath Combo\n') +
    ylab('Number of Properties\n') +
    ggtitle('Short Term Rentals') + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    facet_wrap(~type)

 # Plot  
  
  ggMultiPlots(ltb, stb, cols=1)

```

From this analysis we see that there are 6 combinations that make up most all properties:  1bed/1bath, 2/1, 2/2, 3/1, 3/2 and 4/2. We filter the data to these combinations.  

```{r filtBB3, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 # Set level of acceptable combinations

  acc.bb <- c('1..1', '2..1', '2..2', '3..1', '3..2', '4..2')

 # Filter data

  ltr.data <- ltr.data[ltr.data$bedbath %in% acc.bb, ]
  abb.data <- abb.data[abb.data$bedbath %in% acc.bb, ]

  countCleaning('bedbath')

```

Finally, we re-order the factor levels on the bed/bath combinations to make a 2-bed, 2-bath house or apartment the control case in future statistical models.  We additionally create a product variable that splits the bed/bath by apartment and house.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Re-order factors

  abb.data$bedbath <- factor(abb.data$bedbath, 
                              levels=c('2..2', '1..1', '2..1', '3..1', '3..2', '4..2'))
  ltr.data$bedbath <- factor(ltr.data$bedbath, 
                               levels=c('2..2', '1..1', '2..1', '3..1', '3..2', '4..2'))

  # Add product as a variable
  
  abb.data$product <- paste0(substr(abb.data$type, 1, 1), abb.data$bedbath)
  ltr.data$product <- paste0(substr(ltr.data$type, 1, 1), ltr.data$bedbath)

```


## Rates and Rental values

We now turn to filtering by the prices -- the nightly rates and weekly rental values.  We start by removing observations missing price data. 

```{r ltprice_fltr, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  ltr.data <- ltr.data[!is.na(ltr.data$event.price), ]
  abb.data <- abb.data[!is.na(abb.data$nightly.rate), ]
  
```

Next, we convert the Airbnb values to Australian dollars from US dollars using the exchange rate specified above (1.32).

```{r exch_rate_adj, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Property level data

  abb.data$average.daily.rate <- abb.data$average.daily.rate * exch.rate
  abb.data$nightly.rate <- abb.data$nightly.rate * exch.rate
  abb.data$weekly.rate <- abb.data$weekly.rate * exch.rate
  abb.data$monthly.rate <- abb.data$monthly * exch.rate
  
  # Daily data
  
  daily.data$price <- daily.data$price * exch.rate

```

```{r ltprice_fltr2, message=FALSE, warning=FALSE, comment=FALSE, cache=FALSE, echo=TRUE}

  # ltr Plot
  
  ltr.plot <- ggplot(ltr.data, aes(x=event.price)) + 
    geom_density(fill=ltr.col, alpha=.8) +
    ylab('') +
    xlab('Weekly Rental') + 
    ggtitle('Long Term Rentals') + 
    scale_x_continuous(limits=c(0, 1500)) +
    theme(axis.title.y=element_blank(),
          axis.text.y=element_blank(),
          axis.ticks.y=element_blank())

  # Nightly Rate plot
  rate.plot <- ggplot(abb.data, aes(x=nightly.rate)) + 
    geom_density(fill=str.col, alpha=.8) + 
    ylab('') +
    xlab('Nightly Rate') +
    ggtitle('Short Term Rentals') + 
    scale_x_continuous(limits=c(0, 600)) +
    theme(axis.title.y=element_blank(),
          axis.text.y=element_blank(),
          axis.ticks.y=element_blank())

```

```{r ltprice_fltr2s, message=FALSE, warning=FALSE, comment=FALSE, cache=FALSE, echo=TRUE}

  ggMultiPlots(ltr.plot, rate.plot, cols=2)

```

From these density plots we see that most weekly Rentals are greater than $200 and less than $1000 per week while most nightly rates are greater than $50 and less than $500 per night. We filter the data accordingly. 

```{r ltprice_fltr3, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 ## Filter the long term data

  ltr.data <- ltr.data[ltr.data$event.price >= 200 & 
                         ltr.data$event.price <= 1000, ]

 ## Filter the short term data

  abb.data <- abb.data[abb.data$nightly.rate >= 50 &
                         abb.data$nightly.rate <= 500, ]

  countCleaning('rates.rents')
  
  
```

### Locations and Submarkets

Location is clearly an important determinant in both the short and long term rental markets. At the broadest scale, the long-term Melbourne residential market is usually discussed in terms of Inner, Middle and Outer suburbs.  In general, prices are highest in the inner suburbs and lowest in the outer, with a number of exceptions in the high end neighborhoods in the east and southeastern areas of the middle suburbs.  Suburbs in Melbourne are much smaller than their North American counterparts.  The specific suburb of a property is the second, or finer scale, at which the market operates. The plot below shows the three large submarkets (Inner, Middle and Outer).

```{r mappoints, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 # Convert shapefile to ggplot-able object
  
  # Fix lat/long
 
  # Limit to extent of data
  sub.table <- table(ltr.data$suburb)
  sub.table <- sub.table[sub.table != 0]
  
  # Clip to only those with a ltral observation
  study.suburbs <- suburbs.shp[suburbs.shp@data$name_2006 %in% names(sub.table),]
  
  # Convert to an outer bound with holes
  ss.bound <- gUnaryUnion(study.suburbs)
  
  # Remove holes from the shapefile
  ssb <- slot(ss.bound, "polygons") 
  holes <- lapply(ssb, function(x) sapply(slot(x, "Polygons"), 
                                          slot, "hole"))
  res <- lapply(1:length(ssb), function(i) slot(ssb[[i]], "Polygons")[!holes[[i]]]) 
  IDs <- row.names(ss.bound) 
  ssb.fill <- SpatialPolygons(lapply(1:length(res), function(i) 
   Polygons(res[[i]], ID=IDs[i])), proj4string=CRS(proj4string(ss.bound))) 
  
  # Identify which suburbs all in area covered by outer bound
  ss.in <- gIntersects(suburbs.shp, ssb.fill, byid=T)
  study.suburbs <- suburbs.shp[which(ss.in), ]
  
  # Convert into a ggplot-able format
  subs <- fortify(study.suburbs, region='name_2006')

  # Add suburb category
  subs$des <- suburbs.shp@data$suburbdesi[
    match(subs$id, suburbs.shp@data$name_2006)]

```

```{r mappoints2, message=FALSE, warning=FALSE, comment=FALSE, cache=FALSE, echo=TRUE}

 ## Build the map object

  # Set colors
  g.cols <- abb.col[c(2, 10, 9)]

  # Make map
  loc.map <- ggplot() +
    geom_polygon(data=subs, aes(x=long, y=lat, group=group, fill=des), alpha=.8) + 
    scale_fill_manual(values=g.cols, labels=c('Inner      ',
                                              'Middle      ',
                                              'Outer')) +
    geom_path(data=subs, aes(x=long, y=lat, group=group), col='gray40') +
    scale_x_continuous(limits=c(min(subs$long), max(subs$long))) +
    scale_y_continuous(limits=c(min(subs$lat), max(subs$lat))) +
    xlab('') + ylab('')+
    theme(legend.position = 'bottom',
          legend.title = element_blank()) +
    ggtitle("Melbourne Suburb Classifications")

```

```{r plot_loc_map, message=FALSE, warning=FALSE, comment=FALSE, cache=FALSE, echo=TRUE, fig.height=6}

  loc.map  

```

It is likely that the short-term rental market follows a similar market hierarchy, however, we can imagine that a few different spatial features can influence the short-term market.  While there are many possible additional features, we consider two to be the most likely to influence rates or occupancy: 1) Proximity to beach; and 2) Proximity to key tourist activities and events.  Using the three broad submarkets from the long-term market (inner, middle and outer) we have created a five sub-market system as a starting point for spatially analysing short and long term ltrals in Melboure:

1. Rural (Outer suburbs, not Beach)
2. Suburban (Middle suburbs, not Beach)
3. City (Inner Suburbs, not Beach, not Core)
4. City-Core (Select inner suburbs with tourist activities and near CBD)
5. Beach (Properties within 500m of Port Phillip Bay east of Yarra River)

We assign these designations by: 1) Adding suburb designations to the properties; 2) Assigning submarkets 1-4 based on suburb location; and 3) Indicating proximity to beach and labeling as 'Beach' submarket.  This process is repeated for both the short and long term data.  We also add the Statistical Area 1 code for each property for use in additional spatial modeling later on. Finally, we also remove any observations that fall outside of outer suburbs (the extent of the suburbs). 

We select the 18 suburbs below to represent the 'core' of the city.  The majority of tourist destinations and major events such as the Australian Open and the Grand Prix are located in these suburbs.  All are well serviced by public transportation and possess abundant amenties for tourists. 

```{r core_suburbs, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 core.suburbs <- c('Albert Park', 'Carlton', 'Collingwood', 'Cremorne', 'Docklands',
                   'East Melbourne', 'Fitzroy', 'Melbourne', 'Port Melbourne', 'Prahran',
                   'Richmond', 'South Melbourne', 'South Yarra', 'Southbank', 'St Kilda',
                   'St Kilda West', 'West Melbourne', 'Windsor')

```

We then apply a 500 meter buffer to the beach along Port Phillip Bay. 

```{r beachbuffer, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 # Determine centroid of study area
 
  latMid <- median(abb.data$latitude)
  longMid <- median(abb.data$longitude)

 # Calculate Degress to Meters conversion 
 
  m.lat = 111132.954 - 559.822 * cos(2 * latMid) + 1.175 * cos(4 * latMid)
  m.long = 111132.954 * cos (latMid)
  m.conv <- mean(m.lat, m.long)
 
 # Create the beach buffer  
  
  beach.buffer <- gBuffer(beach.shp, byid=FALSE, width=500/m.conv)

```

Next we assign the suburb, SA1, city-core and beach designations to observations in the Airbnb dataset.  

```{r add_st_space, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 ## Short term data  

  # Convert to point shapefile
  abb.prop.shp <- SpatialPointsDataFrame(cbind(abb.data$longitude,
                                               abb.data$latitude),
                                         abb.data,
                                         proj4string=CRS("+init=epsg:4283")) 

  # Add suburb name 
  spJoin <- over(abb.prop.shp, suburbs.shp)
  abb.data$suburb <- as.character(spJoin$name_2006)
  abb.data$suburb[is.na(abb.data$suburb)] <- 'missing'

  # Add suburb designation
  abb.data$sub.class <- as.character(spJoin$suburbdesi)
  abb.data$sub.class[is.na(abb.data$sub.class)] <- 'missing'
  
  # Add SA1 designation
  spJoin <- over(abb.prop.shp, sa1s.shp)
  abb.data$sa1 <- spJoin$sa1_main11
 
  ## Add Beach Designation
  spJoin <- over(abb.prop.shp, beach.buffer)
  abb.data$beach <- ifelse(is.na(spJoin), 0 ,1)
  
  # Remove those missing a suburb classification (out of area)
  abb.data <- abb.data[abb.data$sub.class != 'missing', ]
  abb.data <- abb.data[abb.data$sa1 != 'missing', ]

```

```{r convert_st_subm, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 ## Add the submarket designations

  # Add individual classes
  abb.data$sub.mrkt <- 'rural'
  abb.data$sub.mrkt[abb.data$sub.class == 'Middle'] <- 'suburban'
  abb.data$sub.mrkt[abb.data$sub.class == 'Inner'] <- 'city'
  abb.data$sub.mrkt[abb.data$suburb %in% core.suburbs] <- 'city-core'
  abb.data$sub.mrkt[abb.data$beach == 1] <- 'beach'
  
  # Order the factors properly
  abb.data$sub.mrkt <- factor(abb.data$sub.mrkt, 
                              levels=c('city-core', 'city', 'suburban', 
                                        'rural', 'beach'))
  
```

Before we do the same for the long term data, we must remedy the fact that about 5% of the long term rental observations have missing latitude and longitude values.  Half of these do, however, have a lat/long value for the centroid of the street that the property faces.  To retain as many observations as possible in these intial steps for those properties that lack a specific lat/long value we apply the street centroid value.  For those without either (3% of the total) we remove them from the dataset at this point. 

```{r fix_ltt_geo, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 # Label those missing lat/long  

  miss.LL <- which(is.na(ltr.data$latitude))  

 # Create a field to indicate the approximate matches  

  ltr.data$miss.LL <- 0
  ltr.data$miss.LL[miss.LL] <- 1

 # Apply approximate match    

  ltr.data$latitude[miss.LL] <- ltr.data$street.latitude[miss.LL]
  ltr.data$longitude[miss.LL] <- ltr.data$street.longitude[miss.LL]

 # Remove those still missing latitude data   

  ltr.data <- ltr.data[!is.na(ltr.data$latitude), ]

```

Having fixed the missing lat/long issue, we then assign the suburb, SA1, city-core and beach designations to observations in the long term rental dataset.  

```{r add_lt_space, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Long term data  

  # Convert to point shapefile

  ltr.prop.shp <- SpatialPointsDataFrame(cbind(ltr.data$longitude,
                                               ltr.data$latitude),
                                         ltr.data,
                                         proj4string=CRS("+init=epsg:4283")) 

  # Add suburb name 
  
  spJoin <- over(ltr.prop.shp, suburbs.shp)
  ltr.data$suburb <- as.character(spJoin$name_2006)
  ltr.data$suburb[is.na(ltr.data$suburb)] <- 'missing'

  # Add suburb designation
  
  ltr.data$sub.class <- as.character(spJoin$suburbdesi)
  ltr.data$sub.class[is.na(ltr.data$sub.class)] <- 'missing'
  
  # Add SA1 designation
  
  spJoin <- over(ltr.prop.shp, sa1s.shp)
  ltr.data$sa1 <- spJoin$sa1_main11
 
  ## Add Beach Designation
  
  spJoin <- over(ltr.prop.shp, beach.buffer)
  ltr.data$beach <- ifelse(is.na(spJoin), 0 ,1)
  
  # Remove those missing a suburb classification (out of area)
  
  ltr.data <- ltr.data[ltr.data$sub.class != 'missing', ]
  ltr.data <- ltr.data[ltr.data$sa1 != 'missing', ]

```

```{r convert_lt_subm, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 ## Add the submarket designations

  # Add individual classes
  ltr.data$sub.mrkt <- 'rural'
  ltr.data$sub.mrkt[ltr.data$sub.class == 'Middle'] <- 'suburban'
  ltr.data$sub.mrkt[ltr.data$sub.class == 'Inner'] <- 'city'
  ltr.data$sub.mrkt[ltr.data$suburb %in% core.suburbs] <- 'city-core'
  ltr.data$sub.mrkt[ltr.data$beach == 1] <- 'beach'
  
  # Order the factors properly
  ltr.data$sub.mrkt <- factor(ltr.data$sub.mrkt, 
                              levels=c('city-core', 'city', 'suburban', 
                                        'rural', 'beach'))
  
  countCleaning('location')
  
```

```{r write_afterspobj, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

after.SP <- list(abb.data=abb.data,
                 ltr.data=ltr.data)


save(after.SP, file="C:/Dropbox/Research/airBNB/data/analyzed/abb_afterSP.RData")


```

The location of the short and long term rentals, colored by submarket, are shown below

```{r abb.plot, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Set submarket colors
  
  sm.col <- abb.col[c(1, 3, 6, 5, 2)]

  # Make map

  abb.map <- ggplot() +
    geom_polygon(data=subs, aes(x=long, y=lat, group=group), color='gray50') +
    geom_point(data=abb.data, aes(x=longitude, y=latitude, color=sub.mrkt), size=.2,
               alpha=.2) +
    scale_color_manual(values=sm.col) +
    scale_x_continuous(limits=c(min(subs$long), max(subs$long))) +
    scale_y_continuous(limits=c(min(subs$lat), max(subs$lat))) +
    xlab('') + ylab('')+
    theme(legend.position = 'bottom',
          legend.title = element_blank()) +
    guides(colour = guide_legend(override.aes = list(size=3,
                                                     alpha=1))) + 
    ggtitle('AirBNB Location\nBy Submarket')
  
```

```{r ltr.plot, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Make map

  ltr.map <- ggplot() +
    geom_polygon(data=subs, aes(x=long, y=lat, group=group), color='gray50') +
    geom_point(data=ltr.data, aes(x=longitude, y=latitude, color=sub.mrkt), size=.1,
               alpha=.1) +
    scale_color_manual(values=sm.col) +
    scale_x_continuous(limits=c(min(subs$long), max(subs$long))) +
    scale_y_continuous(limits=c(min(subs$lat), max(subs$lat))) +
    xlab('') + ylab('')+
    theme(legend.position = 'bottom',
          legend.title = element_blank()) +
    guides(colour = guide_legend(override.aes = list(size=3,
                                                     alpha=1))) + 
    ggtitle('Long Term Rental Location\nBy Submarket')
  
```

```{r loc.plot, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE, fig.width=9}

  ggMultiPlots(abb.map, ltr.map, cols=2)

```

The chart below break down the relative frequency of short and long term rental properties across the five submarkets. 

```{r smtype.plot, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE, fig.width=9}

  # Make Airbnb submarket map
  
  abbtype.map <- ggplot() +
    geom_bar(data=abb.data, aes(x=sub.mrkt, fill=sub.mrkt)) +
    scale_fill_manual(values=sm.col) +
    facet_wrap(~type) +
    ylab('# of Properties\n') + xlab('')+
    theme(legend.position = 'bottom',
          legend.title = element_blank(),
          axis.text.x=element_blank(),
          axis.ticks.x=element_blank()) +
    ggtitle('AirBNB Property Type\nBy Submarket')
  
  # Make Long term rental map

  ltrtype.map <- ggplot() +
    geom_bar(data=ltr.data, aes(x=sub.mrkt, fill=sub.mrkt)) +
    scale_fill_manual(values=sm.col) +
    facet_wrap(~type) +
    ylab('# of Properties\n') + xlab('')+
    theme(legend.position = 'bottom',
          legend.title = element_blank(),
          axis.text.x=element_blank(),
          axis.ticks.x=element_blank()) +
    ggtitle('Long Term Property Type\nBy Submarket')
  
```


```{r loctype.plot, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE, fig.width=9}

  ggMultiPlots(abbtype.map, ltrtype.map, cols=2)

```

Finally, we convert the suburb names from factors to character, which will help with the imputation exercises later on. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Convert suburbs from factor to character
  abb.data$suburb <- as.character(abb.data$suburb)
  ltr.data$suburb <- as.character(ltr.data$suburb)
  
```

&nbsp;


## Filter Transaction Data

The previous exercises filtered the property-level data.  We now filter the transaction level datasets so that they only include those property that remain in the filtered property-level datasets

```{r filttransdata, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 ## Short term data
  
  daily.data <- daily.data[daily.data$property.id %in% abb.data$property.id,]

 ## Long term list data
  
  listing.data <- listing.data[listing.data$activity.id %in% ltr.data$activity.id,]

```

## Revenue Estimation

We now turn to calculating the revenues for each property under an Airbnb and a long term rental scenario.  Before we start, there are few additional data prepartion tasks to undertake. 

First we calculate the total number of bookings, the occupancy rate, blocked rate and proportion of the year over which the property was listed for the Airbnb properties only. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
  # Determine # of booking for each airbnb
  abb.data$bookings <- (abb.data$total.days - 
                          abb.data$blocked.days - 
                           abb.data$available.days)
  
  # Determine property specific occupancy rate
  abb.data$occ.rate <- (abb.data$bookings / 
                           (abb.data$total.days - abb.data$blocked.days))
  
  # Set the blocked rate
  abb.data$blocked.rate <- abb.data$blocked.days / abb.data$total.days
  
  # Set the extrapolation parameter for those on the site for less than whole period
  abb.data$extr.par <- 366 / abb.data$total.days

```

Next we extract all of the daily reservation data that fits our criteria -- reserved, not imputed and not over $500 per night^[Note that there are some outlying daily observations that do not agree with the property level Airbnb summary data.  We do this step to remove those]. From this information we calculate the median nightly reservation price for each property and append it to the property level data. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Get all of the reservations
  resv.daily <- daily.data[daily.data$status == 'R' &
                             daily.data$booked.date != 'imputed' &
                              daily.data$price < 500, ]
  
  # Calculate the property specific median nightly rate
  med.daily <- tapply2DF(resv.daily$price, resv.daily$property.id, median)
  
  # Add median rate to the property  
  abb.data$med.rate <- med.daily$Var[match(abb.data$property.id, med.daily$ID)] 
  
```

### Actual Revenues

In this section we total up the actual revenues for each short and long term rental property.

For the Airbnb properties we then calculate the actual revenue over the Sep 1 2015 to Aug 31 2016 period. Those with no revenue are removed. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Calculate the total revenue  
  abb.data$revenue <- (abb.data$med.rate * exch.rate * 
                          abb.data$extr.par * abb.data$bookings)
  
  # Remove those with no revenue
  abb.data <- abb.data[!is.na(abb.data$revenue), ]

```

Next, we calculate the revenue for the long term rental data, saving only those with revenue of at least $5,000 (less than this represented properties with very long days on market.)

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Calculate the actual revenue
  ltr.data$revenue <- ltr.data$event.price * (52 - ltr.data$dom / 7)
  
  # Remove those with very low revenues (due to very long DOMs)
  ltr.data <- ltr.data[ltr.data$revenue > 5000, ]
  
  countCleaning('revenue')

```

#### Costs

SAVE HERE FOR SUBTRACTION OF COSTS FROM REVENUE

Finally, we create and fix three variables. One factor variable for bed/bath combination, a factor variable that splits bed/bath by house and apartment and then we convert suburb from a factor to a character. 

### Save Workspace for using in 'Working' script

```{r savewrkspc, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  #save.image("C:/Dropbox/Research/airBNB/data/analyzed/abb_working.RData")
  save(abb.data, listing.data, daily.data, ltr.data, subs, abb.col, clean.count,
       file="C:/Dropbox/Research/airBNB/data/analyzed/abb_working.RData")


```

## Global Market Analysis

We now analyze the full metro market to test which properties are more profitable as short-term rentals.  

We start by specifying the imputation models for the LTR and the Airbnb datasets

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  ltr.mod.spec <- formula(log(event.price) ~ as.factor(type) + 
                            as.factor(bedbath) + as.factor(suburb) + 
                            as.factor(ltr.month))
  abb.mod.spec <- formula(log(nightly.rate) ~ as.factor(type) + 
                            as.factor(bedbath) + as.factor(suburb))

```

We then employ a custom function to cross impute rates and rents for the two datasets.  The 'clip.field' is a spatial fixed effects that add spatial recognition to the models. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
  imp.data <- imputeRatesRents(ltr.df=ltr.data, 
                               abb.df=abb.data, 
                               ltr.mod.spec=ltr.mod.spec, 
                               abb.mod.spec=abb.mod.spec,
                               clip.field='suburb')

```

From the imputed results, we extract the base data (with imputed values) as well as the model summaries. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Extract out DFs (only those that imputed)
  abb.imp <- imp.data$abb
  ltr.imp <- imp.data$ltr
  
  # Extract models
  abb.sum <- summary(imp.data$abb.mod)
  ltr.sum <- summary(imp.data$ltr.mod)

```

We use the base data to impute the likely annual revenue for each tenure type (within tenure). These estimates are added back to the base data.   

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  imp.revs <- revenueEngine(abb.imp, 
                            ltr.imp,
                            rate.field='imp.rate',
                            rent.field='imp.rent')

  abb.imp$imp.revenue <- imp.revs$abb
  ltr.imp$imp.revenue <- imp.revs$ltr
  

```

Next we cross impute days on market and occupancy rates.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Apply dom to abb
  abb.imp$imp.dom <- imputeDOM(abb.imp, ltr.imp, calc.type='median')
  
  # Apply occ.rate to ltr
  ltr.imp$imp.occ <- imputeOccRate(ltr.imp, abb.imp, calc.type='median')
  

```

With the cross-imputed DOMs and occupancy rates we now make the cross-tenure imputations of revenues and add them back to the original datasets. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  impx.revs <- revenueEngine(abb.df=ltr.imp, 
                             ltr.df=abb.imp,
                             rate.field='imp.rate',
                             rent.field='imp.rent',
                             occ.field='imp.occ',
                             dom.field='imp.dom')

  abb.imp$imp.ltr.revenue <- impx.revs$ltr
  ltr.imp$imp.abb.revenue <- impx.revs$abb
  
```

Next, we compare the revenues from the two and extract the new datasets.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  comp.revs <- compareRevenues(abb.imp, ltr.imp)
  
  abb.revs <- comp.revs$abb
  ltr.revs <- comp.revs$ltr

```

### Analyze Results

First we make a comparison table of the results, broken down by submarket.  

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  mrkt.table <- createCompTable(abb.revs, ltr.revs, 'sub.mrkt')
  mrkt.table$ID <- factor(mrkt.table$ID, 
                          levels=c('city-core', 'city', 'suburban', 'rural', 'beach'))
  
```

We plot these results in a 2x2 matrix to show the preference likelihoods under the 4 possible scenarios. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
 twotwo.bar.plot <- 
    ggplot(mrkt.table, 
                            aes(x=ID, weights=Var, fill=ID)) + 
    geom_bar() +
    facet_grid(est ~ data) +
    scale_fill_manual(values=sm.col) +
    xlab('') +
    ylab('% of properties where Airbnb is more profitable') +
    scale_y_continuous(breaks=c(0,.25,.5,.75,1),
                       labels=c('0%', '25%', '50%', '75%', '100%')) +
    theme(legend.position='none')

```

We find the results from the four highly variable.  Much of this is due to the unreliability of the occupancy and nightly rate estimates for the LTR data.  We build a set of diagrams and charts to explain the differences.

First, we build out the information for each diagram

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 mrkt.table$est[c(1:5, 11:15)] <- 'Imp. Rates & Rents'
  mrkt.table$x <- 0
  mrkt.table$y <- 0
  mrkt.table$good <- c(rep('bad', 5), rep('good', 5), rep('bad', 10))
                       
  blank.plot <- ggplot(mrkt.table, 
         aes(x=x, y=y)) +
    facet_grid(est ~ data) +
    scale_fill_manual(values=c('salmon', 'lightgreen')) +
    theme(legend.position='none',
          axis.line=element_blank(),
          axis.text.x=element_blank(),
          axis.text.y=element_blank(),
          axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),
          panel.grid.minor = element_blank(),
          panel.grid.major = element_blank()) 
  
  
  ann.df <- data.frame(x=rep(0, 4),
                      y=rep(0, 4), 
                      lab=c(paste0('Airbnb Properties: \n (Actual Airbnb Revenue \n vs.',
                                   '\n Imputed Long Term Revenue)'),
                            paste0('Long-Term Properties: \n (Imputed Airbnb Revenue \n vs.',
                                   '\n Actual Long Term Revenue)'),
                            paste0('Airbnb Properties: \n (Imputed Airbnb Revenue \n vs.',
                                   '\n Imputed Long Term Revenue)'),
                            paste0('Long-Term Properties: \n (Imputed Airbnb Revenue \n vs.',
                                   '\n Imputed Long Term Revenue)')),
                      est=c('Actual Rates & Rents', 'Actual Rates & Rents',
                            'Imp. Rates & Rents', 'Imp. Rates & Rents'),
                      data=c('Airbnb', 'Long-Term', 'Airbnb', 'Long-Term'))
   
  reason.df <- data.frame(x=rep(0, 4),
                       y=rep(0, 4), 
                       lab=c(paste0('+ Actual occupancy rates \n',
                                    '+ Actual nightly rates'),
                             paste0('- Imputed occupancy rates \n',
                                    '- Imputed nightly rate estimates'),
                             paste0('+ Actual occupancy rates \n', 
                                    '- Imputed nightly rate estimates'),
                             paste0('- Imputed occupancy rates \n',
                                    '- Imputed nightly rate estimates')),
                       est=c('Actual Rates & Rents', 'Actual Rates & Rents',
                             'Imp. Rates & Rents', 'Imp. Rates & Rents'),
                       data=c('Airbnb', 'Long-Term', 'Airbnb', 'Long-Term'))
  
  num.df <- data.frame(x=rep(0, 4),
                       y=rep(.8, 4),
                       est=as.factor(c('Actual Rates & Rents', 'Imp. Rates & Rents',
                             'Actual Rates & Rents', 'Imp. Rates & Rents')),
                       data=as.factor(c('Airbnb', 'Airbnb', 'Long-Term', 'Long-Term')),
                       count=c(1,3,2,4))

```

We then construct a plot explaining the data/imputations involved 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
  explain.plot <- blank.plot +
    geom_text(data=ann.df,
              label=ann.df$lab,
              size=3) +
    geom_text(data=num.df,
              label=num.df$count,
              size=9.5) +
    coord_cartesian(ylim=c(-.5,1))

```

And then a plot that gives the reasons for selecting only the upper left scenario.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  reason.plot <- blank.plot +
    geom_rect(data = mrkt.table, aes(fill=good),
              xmin = -Inf,xmax = Inf,
              ymin = -Inf,ymax = Inf, alpha = 0.4) +
    geom_text(data=reason.df,
              label=reason.df$lab,
              size=3) +
    geom_text(data=num.df,
              label=num.df$count,
              size=9.5) +
    coord_cartesian(ylim=c(-.5,1))

```

From the upper left we make a simpler table and plot the preferences by submarket.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  abb.act.table <- mrkt.table[mrkt.table$est == 'Actual Rates & Rents' &
                               mrkt.table$data == 'Airbnb', ]
  
  abb.act.plot <- 
    ggplot(abb.act.table, 
           aes(x=ID, weights=Var, fill=ID)) + 
    geom_bar() +
    scale_fill_manual(values=sm.col) +
    xlab('') +
    ylab('% of properties where Airbnb is more profitable') +
    scale_y_continuous(breaks=c(0,.25,.5,.75,1),
                       labels=c('0%', '25%', '50%', '75%', '100%')) +
    theme(legend.position='none') +
    coord_cartesian(ylim=c(0,1))

```

Next, we plot the \% of properties that have short-term preference versus the occupancy rate

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  rawocc.pplot <- makePrefPlot(abb.revs,
                               x.field='occ.rate',
                               y.field='abb.act',
                               group.field='sub.mrkt',
                               smooth=TRUE,
                               smooth.span=.75)
  rawocc.pplot <- rawocc.pplot +
    xlab('\nOccupancy Rate') +
    ylab('\n% of Properties where Airbnb is more profitable') +
    scale_x_continuous(breaks=seq(0, 100, by=25),
                       labels=c('0%', '25%', '50%', '75%', '100%')) +
    scale_y_continuous(breaks=seq(0, 1, by=.25),
                       labels=c('0%', '25%', '50%', '75%', '100%')) +
    scale_color_manual(values=sm.col)

```

Looking at the distribution of occupancy rates, we that it is not uniform in any of the submarkets.  

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  abb.revs$sub.mrkt <- factor(abb.revs$sub.mrkt, 
                         levels=c('city-core', 'city', 'suburban', 'rural', 'beach'))
  ggplot(abb.revs, aes(x=occ.rate, group=sub.mrkt, color=sub.mrkt, fill=sub.mrkt)) +
    geom_density(alpha=.3) +
    facet_wrap(~sub.mrkt) +
    scale_color_manual(values=sm.col) +
    scale_fill_manual(values=sm.col) +
    scale_x_continuous(breaks=seq(0, 1, by=.5),
                       labels=c('0%', '50%', '100%')) +
    ylab('') +
    xlab('Occupancy Rate') +
    theme(legend.position='none',
          axis.line=element_blank(),
          axis.text.y=element_blank(),
          axis.ticks=element_blank(),
          axis.title.y=element_blank())

```

We then calculate quantile values for rates and replot the charts

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  abb.revs$occ.qtl <- makeWtdQtl(abb.revs$occ.rate, 
                                      return.type='rank') 
  abb.revs$rate.qtl <- makeWtdQtl(abb.revs$med.rate, 
                                  return.type='rank') 
  
  ## Make quartile location plot
  
  qtlocc.pplot <- makePrefPlot(abb.revs,
                               x.field='occ.qtl',
                               y.field='abb.act',
                               group.field='sub.mrkt',
                               smooth=TRUE,
                               smooth.span=.75)
  qtlocc.pplot <- qtlocc.pplot +
    xlab('\nQualtile of Occupancy Rate') +
    ylab('\n% of Properties where Airbnb is more profitable') +
    scale_x_continuous(breaks=seq(0, 100, by=25),
                       labels=c('0', '25th', '50th', '75th', '100th')) +
    scale_y_continuous(breaks=seq(0, 1, by=.25),
                       labels=c('0%', '25%', '50%', '75%', '100%')) +
    scale_color_manual(values=sm.col)

```

Next we build a heat map that shows which combinations of occ rate and nightly rate are most likely to result in short-term preference.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
  rate.hm <- makeHeatMap(abb.revs,
                x.field='occ.rate',
                y.field='nightly.rate',
                color.field='abb.act',
                bins=c(.05, 25),
                svm=F, 
                alpha.count=T,
                add.points=T,
                fill.colors=c(abb.col[1], abb.col[5]))
  
  rate.hm <- rate.hm +
    xlab('\n Occupancy Rate') +
    ylab('\n Nightly Rate') +
    scale_x_continuous(breaks=seq(0, 1, by=.25),
                       labels=c('0%', '25%', '50%', '75%', '100%')) +
    theme(legend.position='bottom')

```

To make the distinction more clear, we employ a Support Vector Machine to classify the areas into short and long term preference. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  rate.hm.svm <- makeHeatMap(abb.revs,
                         x.field='occ.rate',
                         y.field='nightly.rate',
                         color.field='abb.act',
                         bins=c(.05, 25),
                         svm=T, 
                         alpha.count=F,
                         add.points=T,
                         fill.colors=c(abb.col[1], abb.col[5]))
  
  rate.hm.svm <- rate.hm.svm +
    xlab('\n Occupancy Rate') +
    ylab('\n Nightly Rate') +
    scale_x_continuous(breaks=seq(0, 1, by=.25),
                       labels=c('0%', '25%', '50%', '75%', '100%')) +
    theme(legend.position='bottom')
  
```

Again, due to the non-uniformity of distribution of these two axis, we convert to quantiles and re-plot.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
  qtl.hm <- makeHeatMap(abb.revs,
                         x.field='occ.qtl',
                         y.field='rate.qtl',
                         color.field='abb.act',
                         bins=c(5, 5),
                         svm=F, 
                         alpha.count=T,
                         add.points=T,
                         fill.colors=c(abb.col[1], abb.col[5]))
  
  qtl.hm <- qtl.hm +
    xlab('\n Quantile of Occupancy Rate') +
    ylab('\n Quantile of Nightly Rate') +
    scale_x_continuous(breaks=seq(0, 100, by=25),
                       labels=c('0', '25th', '50th', '75th', '100th')) +
    scale_y_continuous(breaks=seq(0, 100, by=25),
                       labels=c('0', '25th', '50th', '75th', '100th')) +
    theme(legend.position='bottom')

```

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
  qtl.hm.svm <- makeHeatMap(abb.revs,
                        x.field='occ.qtl',
                        y.field='rate.qtl',
                        color.field='abb.act',
                        bins=c(5, 5),
                        svm=T, 
                        alpha.count=F,
                        add.points=T,
                        fill.colors=c(abb.col[1], abb.col[5]))
  
  qtl.hm.svm <- qtl.hm.svm +
    xlab('\n Quantile of Occupancy Rate') +
    ylab('\n Quantile of Nightly Rate') +
    scale_x_continuous(breaks=seq(0, 100, by=25),
                       labels=c('0', '25th', '50th', '75th', '100th')) +
    scale_y_continuous(breaks=seq(0, 100, by=25),
                       labels=c('0', '25th', '50th', '75th', '100th')) +
    theme(legend.position='bottom')
  
```

Finally, we calculate the areas of the heat maps and combine into a table. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  svm.rate <- makeSVM(abb.revs,
                     x.field='occ.rate',
                     y.field='nightly.rate',
                     z.field='abb.act',
                     svm.type='C-svc',
                     svm.kernel='polydot',
                     poly.degree=4,
                     expand.factor=100)
  
  svm.qtl <- makeSVM(abb.revs,
                      x.field='occ.qtl',
                      y.field='rate.qtl',
                      z.field='abb.act',
                      svm.type='C-svc',
                      svm.kernel='polydot',
                      poly.degree=4,
                      expand.factor=100)
  
  market.ratio <- data.frame(type=c('rate', 'qtl'),
                             actual=rep(mean(abb.revs$abb.act), 2),
                             fitted=c(mean(svm.rate$orig$fitted),
                                      mean(svm.qtl$orig$fitted)),
                             svm=c(mean(svm.rate$pred$pred),
                                   mean(svm.qtl$pred$pred)))
```

### Submarkets

We now take the analytical process just completed on the entire metro and apply it to various submarkets.  We use a custom function that combines all the processes above into a single command. 

#### Property Type

We start by comparing apartments to houses.  First we set a new imputation model specification

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Set model specifications
  ltr.mod.spec <- formula(log(event.price) ~ as.factor(bedbath) + as.factor(suburb) + 
                            as.factor(ltr.month))
  abb.mod.spec <- formula(log(nightly.rate) ~ as.factor(bedbath) + as.factor(suburb))
  

```

We then recompute the market analysis for each property type.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Select data
  abb.apt <- which(abb.revs$type == 'Apartment')
  ltr.apt <- which(ltr.revs$type == 'Apartment')

  # Estimate House Results  
  house <- fullMarketAnalysis(ltr.df=ltr.revs[-ltr.apt,],
                              abb.df=abb.revs[-abb.apt, ],
                              ltr.mod.spec=ltr.mod.spec,
                              abb.mod.spec=abb.mod.spec,
                              clip.field='suburb',
                              market.field='none',
                              mrkt.col=sm.col,
                              heat.col=c(abb.col[1], abb.col[5]))

   apt <- fullMarketAnalysis(ltr.df=ltr.revs[ltr.apt,],
                             abb.df=abb.revs[abb.apt, ],
                             ltr.mod.spec=ltr.mod.spec,
                             abb.mod.spec=abb.mod.spec,
                             clip.field='suburb',
                             market.field='sub.mrkt',
                             mrkt.col=sm.col,
                             heat.col=c(abb.col[1], abb.col[5]))

```

Below are the quantile heat maps showing the differences in results

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

ggMultiPlots(house$qtl.hm.svm, apt$qtl.hm.svm, cols=2)

```

#### Geographic Submarkets

We now do the same for geographic submarkets

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

# Set model specifications
  ltr.mod.spec <- formula(log(event.price) ~ as.factor(type) + 
                          as.factor(bedbath) +
                          as.factor(suburb) + 
                          as.factor(ltr.month))
  abb.mod.spec <- formula(log(nightly.rate) ~ as.factor(type) + 
                          as.factor(bedbath) +
                          as.factor(suburb))

  #  Extract levels and set capture
  s.levels <- levels(abb.revs$sub.mrkt)
  sm.results <- list()
  sm.pos <- 1

  # Estimate results
  for(sm in s.levels){
  
    abb.x <- which(abb.revs$sub.mrkt == sm)
    ltr.x <- which(ltr.revs$sub.mrkt == sm)
  
    x.res <- fullMarketAnalysis(ltr.df=ltr.revs[ltr.x,],
                                abb.df=abb.revs[abb.x, ],
                                ltr.mod.spec=ltr.mod.spec,
                                abb.mod.spec=abb.mod.spec,
                                clip.field='suburb',
                                market.field='sub.mrkt',
                                mrkt.col=sm.col,
                                heat.col=c(abb.col[1], abb.col[5]))
  
    sm.results[[sm.pos]] <- x.res
    sm.pos <- sm.pos + 1
  
  }
  names(sm.results) <- as.character(s.levels)

```

And for bed/bath combinations

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Set model specifications
  ltr.mod.spec <- formula(log(event.price) ~ as.factor(type) + 
                            as.factor(suburb) + 
                            as.factor(ltr.month))
  abb.mod.spec <- formula(log(nightly.rate) ~ as.factor(type) + 
                            as.factor(suburb))
  
  # Set levels and capture
  bb.levels <- levels(abb.revs$bedbath)
  bb.results <- list()
  bb.pos <- 1

  # Estimate results
  for(bb in bb.levels){
  
    abb.x <- which(abb.revs$bedbath == bb)
    ltr.x <- which(ltr.revs$bedbath == bb)
  
    x.res <- fullMarketAnalysis(ltr.df=ltr.revs[ltr.x,],
                                abb.df=abb.revs[abb.x, ],
                                ltr.mod.spec=ltr.mod.spec,
                                abb.mod.spec=abb.mod.spec,
                                clip.field='suburb',
                                market.field='bedbath',
                                mrkt.col=sm.col,
                                heat.col=c(abb.col[1], abb.col[5]))
  
    bb.results[[bb.pos]] <- x.res
    bb.pos <- bb.pos + 1
  
  }
  names(bb.results) <- as.character(bb.levels)
 

```

And by geo submarket and property type combined

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Set model specifications
  ltr.mod.spec <- formula(log(event.price) ~ as.factor(suburb) + 
                            as.factor(ltr.month))
  abb.mod.spec <- formula(log(nightly.rate) ~ as.factor(suburb))
  
  # Create smt variable  
  abb.revs$smt <- as.factor(paste0(abb.revs$type, '.', abb.revs$sub.mrkt))
  ltr.revs$smt <- as.factor(paste0(ltr.revs$type, '.', ltr.revs$sub.mrkt))

  # Create levels and captures
  smt.levels <- levels(abb.revs$smt)
  smt.results <- list()
  smt.pos <- 1

  # Estimate the smt models
  for(smt in smt.levels){
  
    abb.x <- which(abb.revs$smt == smt)
    ltr.x <- which(ltr.revs$smt == smt)
  
    x.res <- fullMarketAnalysis(ltr.df=ltr.revs[ltr.x,],
                                abb.df=abb.revs[abb.x, ],
                                ltr.mod.spec=ltr.mod.spec,
                                abb.mod.spec=abb.mod.spec,
                                clip.field='suburb',
                                market.field='smt',
                                mrkt.col=sm.col,
                                heat.col=c(abb.col[1], abb.col[5]))
  
    smt.results[[smt.pos]] <- x.res
    smt.pos <- smt.pos + 1
  }
  names(smt.results) <- as.character(smt.levels)

```

### Further analysis

The above present, essentially, univariate analyses of each of the submarkets in question.  While illustrative, they do not hold constant other differences in co-variates that might affect short term preference.  To better control for these influences we estimate a set of logistic regression model to estimate the impact of various variables on short-term preference.

Before we begin, we do a bit of data preparation: extracting abb data and fixing the cancellation policy variable.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  smt.data <- rbind.fill(lapply(smt.results, function(x) x$abb))
  
  ss60 <- which(smt.data$cancel.policy == 'Super Strict 60 Days')
  smt.data$cancel.policy[ss60] <- 'Strict'
  cpmiss <- which(smt.data$cancel.policy == '')
  smt.data <- smt.data[-cpmiss, ]
  

```

First, we look only at structural characteristics.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  mod.str <- glm(abb.act~type+as.factor(bedbath),
                 family=binomial(link='logit'),
                 data=smt.data)

```

We then add geographic submarkets.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

   mod.sm <- glm(abb.act~type+as.factor(bedbath)+
                  sub.mrkt,
                 family=binomial(link='logit'),
                 data=smt.data)

```

And, finally, host policy actions. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

   mod.host <- glm(abb.act~type+as.factor(bedbath)+
                    sub.mrkt+
                    I(max.guests/bedrooms)+min.stay+
                    I(cancel.policy=='Flexible') + I(cancel.policy=='Strict'),
                  family=binomial(link='logit'),
                  data=smt.data)

```

We add suburb fixed effects and re-estimate the str and host models. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Suburb model
  mod.sub <- glm(abb.act~type+as.factor(bedbath)+
                   suburb,
                 family=binomial(link='logit'),
                 data=smt.data)
  
  # Suburb Host model
  mod.subh <- glm(abb.act~type+as.factor(bedbath)+
                  suburb+
                  max.guests+min.stay+
                  I(cancel.policy=='Flexible') + I(cancel.policy=='Strict'),
                  family=binomial(link='logit'),
                  data=smt.data)

```

We then extract the coefficients and diagnostics and build a table for viewing purposes.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 ## Extract Coef
  
  str.ct <- summary(mod.str)$coef
  sm.ct <- summary(mod.sm)$coef
  host.ct <- summary(mod.host)$coef

  # Assign SS
  f.l <- nrow(host.ct)
  assignSS <- function(x){
    
    y<-rep('   ', length(x))
    y[x<.1] <- '*  '
    y[x<.05] <- '** '
    y[x<.01] <- '***'
    
    y
  }
  
  # Build coefs with SS
  str.coef <- sprintf("%.3f" ,str.ct[,1])
  str.sig <- assignSS(str.ct[,4])
  str.coef <- c(paste0(str.coef, str.sig), rep(' ', f.l - nrow(str.ct)))
  
  sm.coef <- sprintf("%.3f" ,sm.ct[,1])
  sm.sig <- assignSS(sm.ct[,4])
  sm.coef <- c(paste0(sm.coef, sm.sig), rep(' ', f.l - nrow(sm.ct)))
  
  host.coef <- sprintf("%.3f" ,host.ct[,1])
  host.sig <- assignSS(host.ct[,4])
  host.coef <- c(paste0(host.coef, host.sig), rep(' ', f.l - nrow(host.ct)))
  
  # Combine into table
  mod.table <- data.frame(Variable=rownames(host.ct),
                          Str.Model=str.coef,
                          Sm.Model=sm.coef,
                          Host.Model=host.coef)
  
  # Fix variable names
  mod.table$Variable <- c('Intercept', 'House', '1Bed/1Bath','2Bed/1Bath',
                          '3Bed/1Bath', '3Bed/2Bath', '4Bed/2Bath', 'City',
                          'Suburban','Rural', 'Beach', 'Guests/Bedroom',
                          'Min. Stay', 'Flexible Cancel', 'Strict Cancel')
  
  
 ## Create model diagnostics  
  
  # Custom function
  logDx <- function(log.model, data, resp.var){
    
    pred <- prediction(predict(log.model, data, type='response'), resp.var)
    auc <- performance(pred, measure='auc')
    ll <- logLik(log.model)
    AIC <- AIC(log.model)
    
    return(list(AIC=AIC,
                logLik=ll,
                auc=auc))
  }
  
  # Extract diagnostics
  str.dx <- logDx(mod.str, smt.data, smt.data$abb.act)
  sm.dx <- logDx(mod.sm, smt.data, smt.data$abb.act)
  host.dx <- logDx(mod.host, smt.data, smt.data$abb.act)
  
  # Create diagnostic table
  diag.table <- data.frame(Variable=c('', 'Diagnostics', 'AIC', 'LogLik', 'AUC'),
                           Str.Model=c('', '', round(str.dx$AIC,0), 
                                       round(str.dx$logLik, 0),
                                       round(as.numeric(str.dx$auc@y.values), 3)),
                           Sm.Model=c('', '', round(sm.dx$AIC,0), 
                                      round(sm.dx$logLik, 0),
                                      round(as.numeric(sm.dx$auc@y.values), 3)),
                           Host.Model=c('', '', round(host.dx$AIC,0), 
                                        round(host.dx$logLik, 0),
                                        round(as.numeric(host.dx$auc@y.values), 3)))
 
 ## Combine into full table of coef and diags
  
 full.table <- rbind(mod.table, diag.table)

```

### Moving Window Logit

To better capture the spatial variation in the logit model results, we set up a moving window logit model that estimates a different model at each estimation point on the map.  Before beginning, we import a new suburbs shapefile and trim it to those suburbs with Airbnb properties. 
```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 suburbs.shp <- readShapePoly(paste0(data.path, 'geographic/melbSuburbs.shp'),
                              proj4string=CRS("+init=epsg:4283"),
                              delete_null_obj=TRUE)

 ssubs <- table(abb.revs$suburb)
 s.subs <- subs[subs$id %in% names(ssubs),]
 s.suburbs <- suburbs.shp[suburbs.shp@data$NAME_2006 %in% names(ssubs),]
 sssubs <- fortify(s.suburbs)
 
```

Next we set up the prediction points.  We drap a grid over the entire area and use those points for prediction points. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 # Min, Max and Range
 xmin <- min(s.subs$long)
 xmax <- max(s.subs$long)
 ymin <- min(s.subs$lat)
 ymax <- max(s.subs$lat)
 xrange <- xmax-xmin
 yrange <- ymax-ymin
 
 # Set Scale
 scale <- mean(xrange, yrange)/100
 
 # Create estimation points
 est.data <- abb.revs
 est.points <- createGridPoints(s.suburbs, scale, T)

```

We then specify the logistic regression model and set the moving window bandwidth. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 ## Set model specification  
 
 mod.spec <- abb.act ~ type + as.factor(bedbath) + 
   I(max.guests / bedrooms) + min.stay + 
   I(cancel.policy == 'Flexible') + 
   I(cancel.policy == 'Strict')
 
 ## Set bandwidth
 
 k <- 400

```

The results are estimated with the custom MWL function

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 mwl.results <- mwl(est.data, 
                    est.points, 
                    mod.spec, 
                    k)
 

```

Coefficents are extracted and put into a data.frame

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

# Extract coef Names
 coef.names <- rownames(mwl.results[[1]])
 
 # Create a list to capture
 coef.list <- list()
 
 # Create a data.frame to capture
 coef.df <- data.frame(lat=est.points@coords[,2],
                       long=est.points@coords[,1])
 
 # Loop through and extract coefficients
 for(cn in 1:length(coef.names)){
   coef.list[[cn]] <- lapply(mwl.results, getMWLCoef, coef=coef.names[cn])
   coef.df[,ncol(coef.df)+1] <- unlist(coef.list[[cn]])
 }
 
 # Add plottable names
 colnames(coef.df)[3:13] <- c('intercept', 'house', 'bb11', 'bb21', 'bb31',
                              'bb32', 'bb42', 'guest', 'minstay', 'flex', 'strict')
 
```

Finally, these coefficients are converted to a surface. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 # Make capture list
 surf.list <- list()
 
 # Create surfaces
 for(sl in 1:ncol(coef.df)){
   
   # If NAs
   to.cut <- which(is.na(coef.df[,sl]))
   if(length(to.cut) > 0){
     surf.points <- est.points[-to.cut,]
     surf.value <- coef.df[-to.cut, sl]
   } else {
     surf.points <- est.points
     surf.value <- coef.df[ , sl]
   }
   
   # Surface estimation
   surf.list[[sl]] <- point2Surface(surf.points, 
                                    surf.value,
                                    .01, 
                                    1.5)
 }

```

```{r working, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

### Save workspace -----------------------------------------------------------------------
  
  save.image("C:/Dropbox/Research/airBNB/data/analyzed/abb_results.RData")

  save(abb.revs, ltr.revs, clean.count, blank.plot,
       rate.hm, rate.hm.svm, qtl.hm, qtl.hm.svm, market.ratio, 
       house, apt, sm.results, full.table, smt.results, bb.results,
       abb.sum, ltr.sum, ann.df, mrkt.table, num.df, reason.df, subs,
       suburbs.shp, s.suburbs, coef.df,
       file="C:/Dropbox/Research/airBNB/data/analyzed/abb_objs.RData")

```












