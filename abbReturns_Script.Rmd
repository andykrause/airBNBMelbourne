---
title: "Should I AirBNB My Property?"
author: "Andy Krause and Gideon Aschwanden"
date: "1 November 2016"
output:
  html_notebook: default
  pdf_document: default
---

&nbsp;

## Introduction

&nbsp;

This document is the literate programming of our analysis for the 'Should I AirBNB My Property?' research project.  Below we document the complete data provenance, taking our data from the raw source data through to the final results. Data prepartion, modeling and visualization will be done in R (version 3.3.1). As a very brief overview, we will be comparing the financial returns of short-term (AirBNB-type) and long-term (traditional leases) leasing of residential properties in Melbourne, Australia.  We perform this comparison under a hypothetical condition where-in an investor purchases a property on Septemeber 1, 2015 and is looking to determine whether to lease out the property on a traditional long-term lease (12 months) or nightly as an AirBNB property.  We examine the returns for the following 12 months.  Sensitivity to time frames, start dates, locations, property types, etc. are considered in this analysis as well. 

Data on AirBNB (short-term) rentals have been purchased from www.airdna.co, a data provider specializing in AirBNB data collection and analysis. The data on long-term leases was provided by Australia Property Monitors (APM), a Fairfax Group company. 

Throughout this document we will refer to the short-term data as **'short-term'** or **'AirBNB'** while the long-term data will be referred to as **'long-term'**, **'rental'** or **'lease'**.  Short-term nightly fees will be referenced as **'rates'** and long-term as **'rent'**.  We will use **'prices'** to collectively refer to **rates** and **rents**. Note that within the Melbourne long term rentals are quoted in weekly rents but are charged to tenants at a monthly rent equivalent to 1/12 of 52 weeks of rent. 

&nbsp;




## Revenue Estimation

We now turn to calculating the revenues for each property under an Airbnb and a long term rental scenario.  Before we start, there are few additional data prepartion tasks to undertake. 

First we calculate the total number of bookings, the occupancy rate, blocked rate and proportion of the year over which the property was listed for the Airbnb properties only. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
  # Set the extrapolation parameter for those on the site for less than whole period
  abb.data$extr.par <- 366 / abb.data$total.days

```


### Actual Revenues

In this section we total up the actual revenues for each short and long term rental property.

For the Airbnb properties we then calculate the actual revenue over the Sep 1 2015 to Aug 31 2016 period. Those with no revenue are removed. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Calculate the total revenue  
  abb.data$revenue <- (abb.data$med.rate * exch.rate * 
                          abb.data$extr.par * abb.data$bookings)
  
  # Remove those with no revenue
  abb.data <- abb.data[!is.na(abb.data$revenue), ]

```

Next, we calculate the revenue for the long term rental data, saving only those with revenue of at least $5,000 (less than this represented properties with very long days on market.)

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Calculate the actual revenue
  ltr.data$revenue <- ltr.data$event.price * (52 - ltr.data$dom / 7)
  
  # Remove those with very low revenues (due to very long DOMs)
  ltr.data <- ltr.data[ltr.data$revenue > 5000, ]
  
  countCleaning('revenue')

```

#### Costs

SAVE HERE FOR SUBTRACTION OF COSTS FROM REVENUE

Finally, we create and fix three variables. One factor variable for bed/bath combination, a factor variable that splits bed/bath by house and apartment and then we convert suburb from a factor to a character. 

### Save Workspace for using in 'Working' script

```{r savewrkspc, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  #save.image("C:/Dropbox/Research/airBNB/data/analyzed/abb_working.RData")
  save(abb.data, listing.data, daily.data, ltr.data, subs, abb.col, clean.count,
       file="C:/Dropbox/Research/airBNB/data/analyzed/abb_working.RData")


```

## Global Market Analysis

We now analyze the full metro market to test which properties are more profitable as short-term rentals.  

We start by specifying the imputation models for the LTR and the Airbnb datasets

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  ltr.mod.spec <- formula(log(event.price) ~ as.factor(type) + 
                            as.factor(bedbath) + as.factor(suburb) + 
                            as.factor(ltr.month))
  abb.mod.spec <- formula(log(nightly.rate) ~ as.factor(type) + 
                            as.factor(bedbath) + as.factor(suburb))

```

We then employ a custom function to cross impute rates and rents for the two datasets.  The 'clip.field' is a spatial fixed effects that add spatial recognition to the models. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
  imp.data <- imputeRatesRents(ltr.df=ltr.data, 
                               abb.df=abb.data, 
                               ltr.mod.spec=ltr.mod.spec, 
                               abb.mod.spec=abb.mod.spec,
                               clip.field='suburb')

```

From the imputed results, we extract the base data (with imputed values) as well as the model summaries. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Extract out DFs (only those that imputed)
  abb.imp <- imp.data$abb
  ltr.imp <- imp.data$ltr
  
  # Extract models
  abb.sum <- summary(imp.data$abb.mod)
  ltr.sum <- summary(imp.data$ltr.mod)

```

We use the base data to impute the likely annual revenue for each tenure type (within tenure). These estimates are added back to the base data.   

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  imp.revs <- revenueEngine(abb.imp, 
                            ltr.imp,
                            rate.field='imp.rate',
                            rent.field='imp.rent')

  abb.imp$imp.revenue <- imp.revs$abb
  ltr.imp$imp.revenue <- imp.revs$ltr
  

```

Next we cross impute days on market and occupancy rates.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Apply dom to abb
  abb.imp$imp.dom <- imputeDOM(abb.imp, ltr.imp, calc.type='median')
  
  # Apply occ.rate to ltr
  ltr.imp$imp.occ <- imputeOccRate(ltr.imp, abb.imp, calc.type='median')
  

```

With the cross-imputed DOMs and occupancy rates we now make the cross-tenure imputations of revenues and add them back to the original datasets. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  impx.revs <- revenueEngine(abb.df=ltr.imp, 
                             ltr.df=abb.imp,
                             rate.field='imp.rate',
                             rent.field='imp.rent',
                             occ.field='imp.occ',
                             dom.field='imp.dom')

  abb.imp$imp.ltr.revenue <- impx.revs$ltr
  ltr.imp$imp.abb.revenue <- impx.revs$abb
  
```

Next, we compare the revenues from the two and extract the new datasets.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  comp.revs <- compareRevenues(abb.imp, ltr.imp)
  
  abb.revs <- comp.revs$abb
  ltr.revs <- comp.revs$ltr

```

### Analyze Results

First we make a comparison table of the results, broken down by submarket.  

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  mrkt.table <- createCompTable(abb.revs, ltr.revs, 'sub.mrkt')
  mrkt.table$ID <- factor(mrkt.table$ID, 
                          levels=c('city-core', 'city', 'suburban', 'rural', 'beach'))
  
```

We plot these results in a 2x2 matrix to show the preference likelihoods under the 4 possible scenarios. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
 twotwo.bar.plot <- 
    ggplot(mrkt.table, 
                            aes(x=ID, weights=Var, fill=ID)) + 
    geom_bar() +
    facet_grid(est ~ data) +
    scale_fill_manual(values=sm.col) +
    xlab('') +
    ylab('% of properties where Airbnb is more profitable') +
    scale_y_continuous(breaks=c(0,.25,.5,.75,1),
                       labels=c('0%', '25%', '50%', '75%', '100%')) +
    theme(legend.position='none')

```

We find the results from the four highly variable.  Much of this is due to the unreliability of the occupancy and nightly rate estimates for the LTR data.  We build a set of diagrams and charts to explain the differences.

First, we build out the information for each diagram

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 mrkt.table$est[c(1:5, 11:15)] <- 'Imp. Rates & Rents'
  mrkt.table$x <- 0
  mrkt.table$y <- 0
  mrkt.table$good <- c(rep('bad', 5), rep('good', 5), rep('bad', 10))
                       
  blank.plot <- ggplot(mrkt.table, 
         aes(x=x, y=y)) +
    facet_grid(est ~ data) +
    scale_fill_manual(values=c('salmon', 'lightgreen')) +
    theme(legend.position='none',
          axis.line=element_blank(),
          axis.text.x=element_blank(),
          axis.text.y=element_blank(),
          axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),
          panel.grid.minor = element_blank(),
          panel.grid.major = element_blank()) 
  
  
  ann.df <- data.frame(x=rep(0, 4),
                      y=rep(0, 4), 
                      lab=c(paste0('Airbnb Properties: \n (Actual Airbnb Revenue \n vs.',
                                   '\n Imputed Long Term Revenue)'),
                            paste0('Long-Term Properties: \n (Imputed Airbnb Revenue \n vs.',
                                   '\n Actual Long Term Revenue)'),
                            paste0('Airbnb Properties: \n (Imputed Airbnb Revenue \n vs.',
                                   '\n Imputed Long Term Revenue)'),
                            paste0('Long-Term Properties: \n (Imputed Airbnb Revenue \n vs.',
                                   '\n Imputed Long Term Revenue)')),
                      est=c('Actual Rates & Rents', 'Actual Rates & Rents',
                            'Imp. Rates & Rents', 'Imp. Rates & Rents'),
                      data=c('Airbnb', 'Long-Term', 'Airbnb', 'Long-Term'))
   
  reason.df <- data.frame(x=rep(0, 4),
                       y=rep(0, 4), 
                       lab=c(paste0('+ Actual occupancy rates \n',
                                    '+ Actual nightly rates'),
                             paste0('- Imputed occupancy rates \n',
                                    '- Imputed nightly rate estimates'),
                             paste0('+ Actual occupancy rates \n', 
                                    '- Imputed nightly rate estimates'),
                             paste0('- Imputed occupancy rates \n',
                                    '- Imputed nightly rate estimates')),
                       est=c('Actual Rates & Rents', 'Actual Rates & Rents',
                             'Imp. Rates & Rents', 'Imp. Rates & Rents'),
                       data=c('Airbnb', 'Long-Term', 'Airbnb', 'Long-Term'))
  
  num.df <- data.frame(x=rep(0, 4),
                       y=rep(.8, 4),
                       est=as.factor(c('Actual Rates & Rents', 'Imp. Rates & Rents',
                             'Actual Rates & Rents', 'Imp. Rates & Rents')),
                       data=as.factor(c('Airbnb', 'Airbnb', 'Long-Term', 'Long-Term')),
                       count=c(1,3,2,4))

```

We then construct a plot explaining the data/imputations involved 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
  explain.plot <- blank.plot +
    geom_text(data=ann.df,
              label=ann.df$lab,
              size=3) +
    geom_text(data=num.df,
              label=num.df$count,
              size=9.5) +
    coord_cartesian(ylim=c(-.5,1))

```

And then a plot that gives the reasons for selecting only the upper left scenario.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  reason.plot <- blank.plot +
    geom_rect(data = mrkt.table, aes(fill=good),
              xmin = -Inf,xmax = Inf,
              ymin = -Inf,ymax = Inf, alpha = 0.4) +
    geom_text(data=reason.df,
              label=reason.df$lab,
              size=3) +
    geom_text(data=num.df,
              label=num.df$count,
              size=9.5) +
    coord_cartesian(ylim=c(-.5,1))

```

From the upper left we make a simpler table and plot the preferences by submarket.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  abb.act.table <- mrkt.table[mrkt.table$est == 'Actual Rates & Rents' &
                               mrkt.table$data == 'Airbnb', ]
  
  abb.act.plot <- 
    ggplot(abb.act.table, 
           aes(x=ID, weights=Var, fill=ID)) + 
    geom_bar() +
    scale_fill_manual(values=sm.col) +
    xlab('') +
    ylab('% of properties where Airbnb is more profitable') +
    scale_y_continuous(breaks=c(0,.25,.5,.75,1),
                       labels=c('0%', '25%', '50%', '75%', '100%')) +
    theme(legend.position='none') +
    coord_cartesian(ylim=c(0,1))

```

Next, we plot the \% of properties that have short-term preference versus the occupancy rate

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  rawocc.pplot <- makePrefPlot(abb.revs,
                               x.field='occ.rate',
                               y.field='abb.act',
                               group.field='sub.mrkt',
                               smooth=TRUE,
                               smooth.span=.75)
  rawocc.pplot <- rawocc.pplot +
    xlab('\nOccupancy Rate') +
    ylab('\n% of Properties where Airbnb is more profitable') +
    scale_x_continuous(breaks=seq(0, 100, by=25),
                       labels=c('0%', '25%', '50%', '75%', '100%')) +
    scale_y_continuous(breaks=seq(0, 1, by=.25),
                       labels=c('0%', '25%', '50%', '75%', '100%')) +
    scale_color_manual(values=sm.col)

```

Looking at the distribution of occupancy rates, we that it is not uniform in any of the submarkets.  

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  abb.revs$sub.mrkt <- factor(abb.revs$sub.mrkt, 
                         levels=c('city-core', 'city', 'suburban', 'rural', 'beach'))
  ggplot(abb.revs, aes(x=occ.rate, group=sub.mrkt, color=sub.mrkt, fill=sub.mrkt)) +
    geom_density(alpha=.3) +
    facet_wrap(~sub.mrkt) +
    scale_color_manual(values=sm.col) +
    scale_fill_manual(values=sm.col) +
    scale_x_continuous(breaks=seq(0, 1, by=.5),
                       labels=c('0%', '50%', '100%')) +
    ylab('') +
    xlab('Occupancy Rate') +
    theme(legend.position='none',
          axis.line=element_blank(),
          axis.text.y=element_blank(),
          axis.ticks=element_blank(),
          axis.title.y=element_blank())

```

We then calculate quantile values for rates and replot the charts

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  abb.revs$occ.qtl <- makeWtdQtl(abb.revs$occ.rate, 
                                      return.type='rank') 
  abb.revs$rate.qtl <- makeWtdQtl(abb.revs$med.rate, 
                                  return.type='rank') 
  
  ## Make quartile location plot
  
  qtlocc.pplot <- makePrefPlot(abb.revs,
                               x.field='occ.qtl',
                               y.field='abb.act',
                               group.field='sub.mrkt',
                               smooth=TRUE,
                               smooth.span=.75)
  qtlocc.pplot <- qtlocc.pplot +
    xlab('\nQualtile of Occupancy Rate') +
    ylab('\n% of Properties where Airbnb is more profitable') +
    scale_x_continuous(breaks=seq(0, 100, by=25),
                       labels=c('0', '25th', '50th', '75th', '100th')) +
    scale_y_continuous(breaks=seq(0, 1, by=.25),
                       labels=c('0%', '25%', '50%', '75%', '100%')) +
    scale_color_manual(values=sm.col)

```

Next we build a heat map that shows which combinations of occ rate and nightly rate are most likely to result in short-term preference.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
  rate.hm <- makeHeatMap(abb.revs,
                x.field='occ.rate',
                y.field='nightly.rate',
                color.field='abb.act',
                bins=c(.05, 25),
                svm=F, 
                alpha.count=T,
                add.points=T,
                fill.colors=c(abb.col[1], abb.col[5]))
  
  rate.hm <- rate.hm +
    xlab('\n Occupancy Rate') +
    ylab('\n Nightly Rate') +
    scale_x_continuous(breaks=seq(0, 1, by=.25),
                       labels=c('0%', '25%', '50%', '75%', '100%')) +
    theme(legend.position='bottom')

```

To make the distinction more clear, we employ a Support Vector Machine to classify the areas into short and long term preference. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  rate.hm.svm <- makeHeatMap(abb.revs,
                         x.field='occ.rate',
                         y.field='nightly.rate',
                         color.field='abb.act',
                         bins=c(.05, 25),
                         svm=T, 
                         alpha.count=F,
                         add.points=T,
                         fill.colors=c(abb.col[1], abb.col[5]))
  
  rate.hm.svm <- rate.hm.svm +
    xlab('\n Occupancy Rate') +
    ylab('\n Nightly Rate') +
    scale_x_continuous(breaks=seq(0, 1, by=.25),
                       labels=c('0%', '25%', '50%', '75%', '100%')) +
    theme(legend.position='bottom')
  
```

Again, due to the non-uniformity of distribution of these two axis, we convert to quantiles and re-plot.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
  qtl.hm <- makeHeatMap(abb.revs,
                         x.field='occ.qtl',
                         y.field='rate.qtl',
                         color.field='abb.act',
                         bins=c(5, 5),
                         svm=F, 
                         alpha.count=T,
                         add.points=T,
                         fill.colors=c(abb.col[1], abb.col[5]))
  
  qtl.hm <- qtl.hm +
    xlab('\n Quantile of Occupancy Rate') +
    ylab('\n Quantile of Nightly Rate') +
    scale_x_continuous(breaks=seq(0, 100, by=25),
                       labels=c('0', '25th', '50th', '75th', '100th')) +
    scale_y_continuous(breaks=seq(0, 100, by=25),
                       labels=c('0', '25th', '50th', '75th', '100th')) +
    theme(legend.position='bottom')

```

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}
  
  qtl.hm.svm <- makeHeatMap(abb.revs,
                        x.field='occ.qtl',
                        y.field='rate.qtl',
                        color.field='abb.act',
                        bins=c(5, 5),
                        svm=T, 
                        alpha.count=F,
                        add.points=T,
                        fill.colors=c(abb.col[1], abb.col[5]))
  
  qtl.hm.svm <- qtl.hm.svm +
    xlab('\n Quantile of Occupancy Rate') +
    ylab('\n Quantile of Nightly Rate') +
    scale_x_continuous(breaks=seq(0, 100, by=25),
                       labels=c('0', '25th', '50th', '75th', '100th')) +
    scale_y_continuous(breaks=seq(0, 100, by=25),
                       labels=c('0', '25th', '50th', '75th', '100th')) +
    theme(legend.position='bottom')
  
```

Finally, we calculate the areas of the heat maps and combine into a table. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  svm.rate <- makeSVM(abb.revs,
                     x.field='occ.rate',
                     y.field='nightly.rate',
                     z.field='abb.act',
                     svm.type='C-svc',
                     svm.kernel='polydot',
                     poly.degree=4,
                     expand.factor=100)
  
  svm.qtl <- makeSVM(abb.revs,
                      x.field='occ.qtl',
                      y.field='rate.qtl',
                      z.field='abb.act',
                      svm.type='C-svc',
                      svm.kernel='polydot',
                      poly.degree=4,
                      expand.factor=100)
  
  market.ratio <- data.frame(type=c('rate', 'qtl'),
                             actual=rep(mean(abb.revs$abb.act), 2),
                             fitted=c(mean(svm.rate$orig$fitted),
                                      mean(svm.qtl$orig$fitted)),
                             svm=c(mean(svm.rate$pred$pred),
                                   mean(svm.qtl$pred$pred)))
```

### Submarkets

We now take the analytical process just completed on the entire metro and apply it to various submarkets.  We use a custom function that combines all the processes above into a single command. 

#### Property Type

We start by comparing apartments to houses.  First we set a new imputation model specification

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Set model specifications
  ltr.mod.spec <- formula(log(event.price) ~ as.factor(bedbath) + as.factor(suburb) + 
                            as.factor(ltr.month))
  abb.mod.spec <- formula(log(nightly.rate) ~ as.factor(bedbath) + as.factor(suburb))
  

```

We then recompute the market analysis for each property type.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Select data
  abb.apt <- which(abb.revs$type == 'Apartment')
  ltr.apt <- which(ltr.revs$type == 'Apartment')

  # Estimate House Results  
  house <- fullMarketAnalysis(ltr.df=ltr.revs[-ltr.apt,],
                              abb.df=abb.revs[-abb.apt, ],
                              ltr.mod.spec=ltr.mod.spec,
                              abb.mod.spec=abb.mod.spec,
                              clip.field='suburb',
                              market.field='none',
                              mrkt.col=sm.col,
                              heat.col=c(abb.col[1], abb.col[5]))

   apt <- fullMarketAnalysis(ltr.df=ltr.revs[ltr.apt,],
                             abb.df=abb.revs[abb.apt, ],
                             ltr.mod.spec=ltr.mod.spec,
                             abb.mod.spec=abb.mod.spec,
                             clip.field='suburb',
                             market.field='sub.mrkt',
                             mrkt.col=sm.col,
                             heat.col=c(abb.col[1], abb.col[5]))

```

Below are the quantile heat maps showing the differences in results

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

ggMultiPlots(house$qtl.hm.svm, apt$qtl.hm.svm, cols=2)

```

#### Geographic Submarkets

We now do the same for geographic submarkets

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

# Set model specifications
  ltr.mod.spec <- formula(log(event.price) ~ as.factor(type) + 
                          as.factor(bedbath) +
                          as.factor(suburb) + 
                          as.factor(ltr.month))
  abb.mod.spec <- formula(log(nightly.rate) ~ as.factor(type) + 
                          as.factor(bedbath) +
                          as.factor(suburb))

  #  Extract levels and set capture
  s.levels <- levels(abb.revs$sub.mrkt)
  sm.results <- list()
  sm.pos <- 1

  # Estimate results
  for(sm in s.levels){
  
    abb.x <- which(abb.revs$sub.mrkt == sm)
    ltr.x <- which(ltr.revs$sub.mrkt == sm)
  
    x.res <- fullMarketAnalysis(ltr.df=ltr.revs[ltr.x,],
                                abb.df=abb.revs[abb.x, ],
                                ltr.mod.spec=ltr.mod.spec,
                                abb.mod.spec=abb.mod.spec,
                                clip.field='suburb',
                                market.field='sub.mrkt',
                                mrkt.col=sm.col,
                                heat.col=c(abb.col[1], abb.col[5]))
  
    sm.results[[sm.pos]] <- x.res
    sm.pos <- sm.pos + 1
  
  }
  names(sm.results) <- as.character(s.levels)

```

And for bed/bath combinations

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Set model specifications
  ltr.mod.spec <- formula(log(event.price) ~ as.factor(type) + 
                            as.factor(suburb) + 
                            as.factor(ltr.month))
  abb.mod.spec <- formula(log(nightly.rate) ~ as.factor(type) + 
                            as.factor(suburb))
  
  # Set levels and capture
  bb.levels <- levels(abb.revs$bedbath)
  bb.results <- list()
  bb.pos <- 1

  # Estimate results
  for(bb in bb.levels){
  
    abb.x <- which(abb.revs$bedbath == bb)
    ltr.x <- which(ltr.revs$bedbath == bb)
  
    x.res <- fullMarketAnalysis(ltr.df=ltr.revs[ltr.x,],
                                abb.df=abb.revs[abb.x, ],
                                ltr.mod.spec=ltr.mod.spec,
                                abb.mod.spec=abb.mod.spec,
                                clip.field='suburb',
                                market.field='bedbath',
                                mrkt.col=sm.col,
                                heat.col=c(abb.col[1], abb.col[5]))
  
    bb.results[[bb.pos]] <- x.res
    bb.pos <- bb.pos + 1
  
  }
  names(bb.results) <- as.character(bb.levels)
 

```

And by geo submarket and property type combined

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Set model specifications
  ltr.mod.spec <- formula(log(event.price) ~ as.factor(suburb) + 
                            as.factor(ltr.month))
  abb.mod.spec <- formula(log(nightly.rate) ~ as.factor(suburb))
  
  # Create smt variable  
  abb.revs$smt <- as.factor(paste0(abb.revs$type, '.', abb.revs$sub.mrkt))
  ltr.revs$smt <- as.factor(paste0(ltr.revs$type, '.', ltr.revs$sub.mrkt))

  # Create levels and captures
  smt.levels <- levels(abb.revs$smt)
  smt.results <- list()
  smt.pos <- 1

  # Estimate the smt models
  for(smt in smt.levels){
  
    abb.x <- which(abb.revs$smt == smt)
    ltr.x <- which(ltr.revs$smt == smt)
  
    x.res <- fullMarketAnalysis(ltr.df=ltr.revs[ltr.x,],
                                abb.df=abb.revs[abb.x, ],
                                ltr.mod.spec=ltr.mod.spec,
                                abb.mod.spec=abb.mod.spec,
                                clip.field='suburb',
                                market.field='smt',
                                mrkt.col=sm.col,
                                heat.col=c(abb.col[1], abb.col[5]))
  
    smt.results[[smt.pos]] <- x.res
    smt.pos <- smt.pos + 1
  }
  names(smt.results) <- as.character(smt.levels)

```

### Further analysis

The above present, essentially, univariate analyses of each of the submarkets in question.  While illustrative, they do not hold constant other differences in co-variates that might affect short term preference.  To better control for these influences we estimate a set of logistic regression model to estimate the impact of various variables on short-term preference.

Before we begin, we do a bit of data preparation: extracting abb data and fixing the cancellation policy variable.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  smt.data <- rbind.fill(lapply(smt.results, function(x) x$abb))
  
  ss60 <- which(smt.data$cancel.policy == 'Super Strict 60 Days')
  smt.data$cancel.policy[ss60] <- 'Strict'
  cpmiss <- which(smt.data$cancel.policy == '')
  smt.data <- smt.data[-cpmiss, ]
  

```

First, we look only at structural characteristics.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  mod.str <- glm(abb.act~type+as.factor(bedbath),
                 family=binomial(link='logit'),
                 data=smt.data)

```

We then add geographic submarkets.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

   mod.sm <- glm(abb.act~type+as.factor(bedbath)+
                  sub.mrkt,
                 family=binomial(link='logit'),
                 data=smt.data)

```

And, finally, host policy actions. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

   mod.host <- glm(abb.act~type+as.factor(bedbath)+
                    sub.mrkt+
                    I(max.guests/bedrooms)+min.stay+
                    I(cancel.policy=='Flexible') + I(cancel.policy=='Strict'),
                  family=binomial(link='logit'),
                  data=smt.data)

```

We add suburb fixed effects and re-estimate the str and host models. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

  # Suburb model
  mod.sub <- glm(abb.act~type+as.factor(bedbath)+
                   suburb,
                 family=binomial(link='logit'),
                 data=smt.data)
  
  # Suburb Host model
  mod.subh <- glm(abb.act~type+as.factor(bedbath)+
                  suburb+
                  max.guests+min.stay+
                  I(cancel.policy=='Flexible') + I(cancel.policy=='Strict'),
                  family=binomial(link='logit'),
                  data=smt.data)

```

We then extract the coefficients and diagnostics and build a table for viewing purposes.

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 ## Extract Coef
  
  str.ct <- summary(mod.str)$coef
  sm.ct <- summary(mod.sm)$coef
  host.ct <- summary(mod.host)$coef

  # Assign SS
  f.l <- nrow(host.ct)
  assignSS <- function(x){
    
    y<-rep('   ', length(x))
    y[x<.1] <- '*  '
    y[x<.05] <- '** '
    y[x<.01] <- '***'
    
    y
  }
  
  # Build coefs with SS
  str.coef <- sprintf("%.3f" ,str.ct[,1])
  str.sig <- assignSS(str.ct[,4])
  str.coef <- c(paste0(str.coef, str.sig), rep(' ', f.l - nrow(str.ct)))
  
  sm.coef <- sprintf("%.3f" ,sm.ct[,1])
  sm.sig <- assignSS(sm.ct[,4])
  sm.coef <- c(paste0(sm.coef, sm.sig), rep(' ', f.l - nrow(sm.ct)))
  
  host.coef <- sprintf("%.3f" ,host.ct[,1])
  host.sig <- assignSS(host.ct[,4])
  host.coef <- c(paste0(host.coef, host.sig), rep(' ', f.l - nrow(host.ct)))
  
  # Combine into table
  mod.table <- data.frame(Variable=rownames(host.ct),
                          Str.Model=str.coef,
                          Sm.Model=sm.coef,
                          Host.Model=host.coef)
  
  # Fix variable names
  mod.table$Variable <- c('Intercept', 'House', '1Bed/1Bath','2Bed/1Bath',
                          '3Bed/1Bath', '3Bed/2Bath', '4Bed/2Bath', 'City',
                          'Suburban','Rural', 'Beach', 'Guests/Bedroom',
                          'Min. Stay', 'Flexible Cancel', 'Strict Cancel')
  
  
 ## Create model diagnostics  
  
  # Custom function
  logDx <- function(log.model, data, resp.var){
    
    pred <- prediction(predict(log.model, data, type='response'), resp.var)
    auc <- performance(pred, measure='auc')
    ll <- logLik(log.model)
    AIC <- AIC(log.model)
    
    return(list(AIC=AIC,
                logLik=ll,
                auc=auc))
  }
  
  # Extract diagnostics
  str.dx <- logDx(mod.str, smt.data, smt.data$abb.act)
  sm.dx <- logDx(mod.sm, smt.data, smt.data$abb.act)
  host.dx <- logDx(mod.host, smt.data, smt.data$abb.act)
  
  # Create diagnostic table
  diag.table <- data.frame(Variable=c('', 'Diagnostics', 'AIC', 'LogLik', 'AUC'),
                           Str.Model=c('', '', round(str.dx$AIC,0), 
                                       round(str.dx$logLik, 0),
                                       round(as.numeric(str.dx$auc@y.values), 3)),
                           Sm.Model=c('', '', round(sm.dx$AIC,0), 
                                      round(sm.dx$logLik, 0),
                                      round(as.numeric(sm.dx$auc@y.values), 3)),
                           Host.Model=c('', '', round(host.dx$AIC,0), 
                                        round(host.dx$logLik, 0),
                                        round(as.numeric(host.dx$auc@y.values), 3)))
 
 ## Combine into full table of coef and diags
  
 full.table <- rbind(mod.table, diag.table)

```

### Moving Window Logit

To better capture the spatial variation in the logit model results, we set up a moving window logit model that estimates a different model at each estimation point on the map.  Before beginning, we import a new suburbs shapefile and trim it to those suburbs with Airbnb properties. 
```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 suburbs.shp <- readShapePoly(paste0(data.path, 'geographic/melbSuburbs.shp'),
                              proj4string=CRS("+init=epsg:4283"),
                              delete_null_obj=TRUE)

 ssubs <- table(abb.revs$suburb)
 s.subs <- subs[subs$id %in% names(ssubs),]
 s.suburbs <- suburbs.shp[suburbs.shp@data$NAME_2006 %in% names(ssubs),]
 sssubs <- fortify(s.suburbs)
 
```

Next we set up the prediction points.  We drap a grid over the entire area and use those points for prediction points. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 # Min, Max and Range
 xmin <- min(s.subs$long)
 xmax <- max(s.subs$long)
 ymin <- min(s.subs$lat)
 ymax <- max(s.subs$lat)
 xrange <- xmax-xmin
 yrange <- ymax-ymin
 
 # Set Scale
 scale <- mean(xrange, yrange)/100
 
 # Create estimation points
 est.data <- abb.revs
 est.points <- createGridPoints(s.suburbs, scale, T)

```

We then specify the logistic regression model and set the moving window bandwidth. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 ## Set model specification  
 
 mod.spec <- abb.act ~ type + as.factor(bedbath) + 
   I(max.guests / bedrooms) + min.stay + 
   I(cancel.policy == 'Flexible') + 
   I(cancel.policy == 'Strict')
 
 ## Set bandwidth
 
 k <- 400

```

The results are estimated with the custom MWL function

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 mwl.results <- mwl(est.data, 
                    est.points, 
                    mod.spec, 
                    k)
 

```

Coefficents are extracted and put into a data.frame

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

# Extract coef Names
 coef.names <- rownames(mwl.results[[1]])
 
 # Create a list to capture
 coef.list <- list()
 
 # Create a data.frame to capture
 coef.df <- data.frame(lat=est.points@coords[,2],
                       long=est.points@coords[,1])
 
 # Loop through and extract coefficients
 for(cn in 1:length(coef.names)){
   coef.list[[cn]] <- lapply(mwl.results, getMWLCoef, coef=coef.names[cn])
   coef.df[,ncol(coef.df)+1] <- unlist(coef.list[[cn]])
 }
 
 # Add plottable names
 colnames(coef.df)[3:13] <- c('intercept', 'house', 'bb11', 'bb21', 'bb31',
                              'bb32', 'bb42', 'guest', 'minstay', 'flex', 'strict')
 
```

Finally, these coefficients are converted to a surface. 

```{r message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

 # Make capture list
 surf.list <- list()
 
 # Create surfaces
 for(sl in 1:ncol(coef.df)){
   
   # If NAs
   to.cut <- which(is.na(coef.df[,sl]))
   if(length(to.cut) > 0){
     surf.points <- est.points[-to.cut,]
     surf.value <- coef.df[-to.cut, sl]
   } else {
     surf.points <- est.points
     surf.value <- coef.df[ , sl]
   }
   
   # Surface estimation
   surf.list[[sl]] <- point2Surface(surf.points, 
                                    surf.value,
                                    .01, 
                                    1.5)
 }

```

```{r working, message=FALSE, warning=FALSE, comment=FALSE, cache=TRUE, echo=TRUE}

### Save workspace -----------------------------------------------------------------------
  
  save.image("C:/Dropbox/Research/airBNB/data/analyzed/abb_results.RData")

  save(abb.revs, ltr.revs, clean.count, blank.plot,
       rate.hm, rate.hm.svm, qtl.hm, qtl.hm.svm, market.ratio, 
       house, apt, sm.results, full.table, smt.results, bb.results,
       abb.sum, ltr.sum, ann.df, mrkt.table, num.df, reason.df, subs,
       suburbs.shp, s.suburbs, coef.df,
       file="C:/Dropbox/Research/airBNB/data/analyzed/abb_objs.RData")

```












